// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 6.2.1 effective-5.10 (swiftlang-6.2.1.4.7 clang-1700.4.4.1)
// swift-module-flags: -target arm64e-apple-macos26.1 -target-variant arm64e-apple-ios26.1-macabi -enable-objc-interop -autolink-force-load -enable-library-evolution -module-link-name swiftAVFoundation -swift-version 5 -enforce-exclusivity=checked -O -library-level api -enable-upcoming-feature StrictConcurrency -enable-experimental-feature DebugDescriptionMacro -enable-bare-slash-regex -user-module-version 2390.10.1 -module-name AVFoundation
// swift-module-flags-ignorable:  -formal-cxx-interoperability-mode=off -interface-compiler-version 6.2.1
@_exported import AVFAudio.AVAudioSession
@_exported import AVFAudio
@_exported import AVFoundation
import CoreGraphics
import CoreImage
import CoreMedia
import Dispatch
import Foundation
import Swift
import Synchronization
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPlayerInterstitialEvent {
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  convenience public init(primaryItem: AVFoundation.AVPlayerItem, identifier: Swift.String?, time: CoreMedia.CMTime, templateItems: [AVFoundation.AVPlayerItem], restrictions: AVFoundation.AVPlayerInterstitialEvent.Restrictions = [], resumptionOffset: CoreMedia.CMTime = .indefinite, playoutLimit: CoreMedia.CMTime = .invalid, userDefinedAttributes: [Swift.String : Any] = [:])
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  convenience public init(primaryItem: AVFoundation.AVPlayerItem, identifier: Swift.String?, date: Foundation.Date, templateItems: [AVFoundation.AVPlayerItem], restrictions: AVFoundation.AVPlayerInterstitialEvent.Restrictions = [], resumptionOffset: CoreMedia.CMTime = .indefinite, playoutLimit: CoreMedia.CMTime = .invalid, userDefinedAttributes: [Swift.String : Any] = [:])
  #endif
}
extension Foundation.NSNotification.Name {
  @available(macOS, introduced: 13.3, deprecated: 14.0, renamed: "AVPlayerInterstitialEventMonitor.assetListResponseStatusDidChangeNotification")
  @available(iOS, introduced: 16.4, deprecated: 17.0, renamed: "AVPlayerInterstitialEventMonitor.assetListResponseStatusDidChangeNotification")
  @available(tvOS, introduced: 16.4, deprecated: 17.0, renamed: "AVPlayerInterstitialEventMonitor.assetListResponseStatusDidChangeNotification")
  @available(watchOS, introduced: 9.4, deprecated: 10.0, renamed: "AVPlayerInterstitialEventMonitor.assetListResponseStatusDidChangeNotification")
  @available(visionOS, introduced: 1, deprecated: 1, renamed: "AVPlayerInterstitialEventMonitor.assetListResponseStatusDidChangeNotification")
  @_alwaysEmitIntoClient public static var AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChange: Foundation.NSNotification.Name {
    get {
		Self("AVPlayerInterstitialEventMonitorAssetListResponseStatusDidChange")
	}
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVMetadataItem {
  #if compiler(>=5.3) && $NonescapableTypes
  public static var extraAttributes: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMetadataExtraAttributeKey : Any]?> {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static var value: AVFoundation.AVAsyncProperty<Root, (any Foundation.NSCopying & ObjectiveC.NSObjectProtocol)?> {
    get
  }
  #endif
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVMetadataItem {
  #if compiler(>=5.3) && $NonescapableTypes
  public static var stringValue: AVFoundation.AVAsyncProperty<Root, Swift.String?> {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static var numberValue: AVFoundation.AVAsyncProperty<Root, Foundation.NSNumber?> {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static var dateValue: AVFoundation.AVAsyncProperty<Root, Foundation.Date?> {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static var dataValue: AVFoundation.AVAsyncProperty<Root, Foundation.Data?> {
    get
  }
  #endif
}
@available(macOS 12, iOS 15, watchOS 8, visionOS 1, *)
@available(tvOS, unavailable)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVMutableMovie {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMutableMovieTrack]> {
    get
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetReaderOutput {
  @_hasMissingDesignatedInitializers public class RandomAccessController {
    public func resetForReading(timeRanges: [CoreMedia.CMTimeRange])
    public func markConfigurationAsFinal()
    @objc deinit
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetReaderOutput {
  public protocol SupportedPayload {
  }
  @_hasMissingDesignatedInitializers public class Provider<Payload> where Payload : AVFoundation.AVAssetReaderOutput.SupportedPayload {
    #if compiler(>=5.3) && $NonescapableTypes && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public func next() async throws -> Payload?
    #endif
    @objc deinit
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension CoreMedia.CMReadySampleBuffer : AVFoundation.AVAssetReaderOutput.SupportedPayload where Content == CoreMedia.CMSampleBuffer.DynamicContent {
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetReader {
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func outputProvider(for output: AVFoundation.AVAssetReaderOutput) -> sending AVFoundation.AVAssetReaderOutput.Provider<CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>>
  #else
  public func outputProvider(for output: AVFoundation.AVAssetReaderOutput) -> AVFoundation.AVAssetReaderOutput.Provider<CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>>
  #endif
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func outputProviderWithRandomAccess(for output: AVFoundation.AVAssetReaderOutput) -> sending (AVFoundation.AVAssetReaderOutput.Provider<CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>>, AVFoundation.AVAssetReaderOutput.RandomAccessController)
  #else
  public func outputProviderWithRandomAccess(for output: AVFoundation.AVAssetReaderOutput) -> (AVFoundation.AVAssetReaderOutput.Provider<CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>>, AVFoundation.AVAssetReaderOutput.RandomAccessController)
  #endif
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVTimedMetadataGroup : AVFoundation.AVAssetReaderOutput.SupportedPayload {
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetReader {
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func outputMetadataProvider(for output: AVFoundation.AVAssetReaderTrackOutput) -> sending AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVTimedMetadataGroup>
  #else
  public func outputMetadataProvider(for output: AVFoundation.AVAssetReaderTrackOutput) -> AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVTimedMetadataGroup>
  #endif
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func outputMetadataProviderWithRandomAccess(for output: AVFoundation.AVAssetReaderTrackOutput) -> sending (AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVTimedMetadataGroup>, AVFoundation.AVAssetReaderOutput.RandomAccessController)
  #else
  public func outputMetadataProviderWithRandomAccess(for output: AVFoundation.AVAssetReaderTrackOutput) -> (AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVTimedMetadataGroup>, AVFoundation.AVAssetReaderOutput.RandomAccessController)
  #endif
}
@available(macOS 26.0, iOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVCaptionGroup : AVFoundation.AVAssetReaderOutput.SupportedPayload {
}
@available(macOS 26.0, iOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVAssetReader {
  #if compiler(>=5.3) && $NonescapableTypes
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func outputCaptionProvider(for output: AVFoundation.AVAssetReaderTrackOutput, validationDelegate: (any AVFoundation.AVAssetReaderCaptionValidationHandling)? = nil) -> sending AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVCaptionGroup>
  #else
  public func outputCaptionProvider(for output: AVFoundation.AVAssetReaderTrackOutput, validationDelegate: (any AVFoundation.AVAssetReaderCaptionValidationHandling)? = nil) -> AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVCaptionGroup>
  #endif
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func outputCaptionProviderWithRandomAccess(for output: AVFoundation.AVAssetReaderTrackOutput, validationDelegate: (any AVFoundation.AVAssetReaderCaptionValidationHandling)? = nil) -> sending (AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVCaptionGroup>, AVFoundation.AVAssetReaderOutput.RandomAccessController)
  #else
  public func outputCaptionProviderWithRandomAccess(for output: AVFoundation.AVAssetReaderTrackOutput, validationDelegate: (any AVFoundation.AVAssetReaderCaptionValidationHandling)? = nil) -> (AVFoundation.AVAssetReaderOutput.Provider<AVFoundation.AVCaptionGroup>, AVFoundation.AVAssetReaderOutput.RandomAccessController)
  #endif
  #endif
}
@available(macOS 26.0, iOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVAssetReaderOutput.Provider where Payload == AVFoundation.AVCaptionGroup {
  public func captionsNotPresentInPreviousGroups(in captionGroup: AVFoundation.AVCaptionGroup) -> [AVFoundation.AVCaption]
}
@available(watchOS 6.0, *)
extension AVFoundation.AVError {
  #if compiler(>=5.3) && $NonescapableTypes
  @available(swift, obsoleted: 4.2, message: "Use `device: AVCaptureDevice?` instead")
  public var device: Swift.String? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(swift 4.2)
  @available(macCatalyst 14.0, tvOS 17.0, *)
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  public var device: AVFoundation.AVCaptureDevice? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(watchOS 6.0, *)
  public var time: CoreMedia.CMTime? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(watchOS 6.0, *)
  public var fileSize: Swift.Int64? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(watchOS 6.0, *)
  public var processID: Swift.Int? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(watchOS 6.0, *)
  public var recordingSuccessfullyFinished: Swift.Bool? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(watchOS 6.0, *)
  @available(swift, obsoleted: 4.2)
  public var mediaType: Swift.String? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(swift 4.2)
  @available(watchOS 6.0, *)
  public var mediaType: AVFoundation.AVMediaType? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(watchOS 6.0, *)
  public var mediaSubtypes: [Swift.Int]? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(swift 4.2)
  @available(macOS 10.10, iOS 8.0, tvOS 9.0, watchOS 6.0, visionOS 1.0, *)
  public var presentationTimeStamp: CoreMedia.CMTime? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(swift 4.2)
  @available(macOS 10.10, iOS 8.0, tvOS 9.0, watchOS 6.0, visionOS 1.0, *)
  public var persistentTrackID: CoreMedia.CMPersistentTrackID? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(swift 4.2)
  @available(macOS 10.10, iOS 8.0, tvOS 9.0, watchOS 6.0, visionOS 1.0, *)
  public var fileType: AVFoundation.AVFileType? {
    get
  }
  #endif
}
@available(macOS 15.0, iOS 18.0, macCatalyst 18.0, tvOS 18.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureIndexPicker {
  @nonobjc public func setActionQueue(_ actionQueue: Dispatch.DispatchQueue, action: @escaping (Swift.Int) -> ())
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVPlayerLayer {
  #if compiler(>=5.3) && $NonescapableTypes
  public func displayedReadOnlyPixelBuffer() -> CoreVideo.CVReadOnlyPixelBuffer?
  #endif
}
@available(macOS 12, iOS 15, watchOS 8, visionOS 1, *)
@available(tvOS, unavailable)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVFragmentedMovie {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVFragmentedMovieTrack]> {
    get
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriterInput {
  @_hasMissingDesignatedInitializers public class MetadataReceiver {
    #if compiler(>=5.3) && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public func append(_ timedMetadataGroup: AVFoundation.AVTimedMetadataGroup) async throws
    #endif
    public func appendImmediately(_ timedMetadataGroup: AVFoundation.AVTimedMetadataGroup) throws -> Swift.Bool
    public func finish()
    @objc deinit
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriter {
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputMetadataReceiver(for input: AVFoundation.AVAssetWriterInput) -> sending AVFoundation.AVAssetWriterInput.MetadataReceiver
  #else
  public func inputMetadataReceiver(for input: AVFoundation.AVAssetWriterInput) -> AVFoundation.AVAssetWriterInput.MetadataReceiver
  #endif
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputMetadataReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput) -> sending (AVFoundation.AVAssetWriterInput.MetadataReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #else
  public func inputMetadataReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput) -> (AVFoundation.AVAssetWriterInput.MetadataReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #endif
}
@available(macOS 26.0, iOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVRenderedCaptionImage {
  public var readOnlyPixelBuffer: CoreVideo.CVReadOnlyPixelBuffer {
    get
  }
}
@available(macOS 10.13, iOS 11.0, macCatalyst 14.0, tvOS 11.0, visionOS 1.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVDepthData {
  @available(macOS 10.13, iOS 11.0, macCatalyst 14.0, tvOS 11.0, visionOS 1.0, *)
  @available(watchOS, unavailable)
  @nonobjc @_alwaysEmitIntoClient public var availableDepthDataTypes: [Darwin.OSType] {
    get {
		return __availableDepthDataTypes.map { $0.uint32Value } as [OSType]
	}
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
extension CoreMedia.CMReadySampleBuffer {
  public mutating func attach(contentKey: AVFoundation.AVContentKey) throws
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVComposition {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVCompositionTrack]> {
    get
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
extension AVFoundation.AVTimedMetadataGroup {
  #if compiler(>=5.3) && $NonescapableTypes
  convenience public init?(sampleBuffer: CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>)
  #endif
}
@available(macOS 26.0, iOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVAssetWriterInput {
  @_hasMissingDesignatedInitializers public class CaptionReceiver {
    #if compiler(>=5.3) && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public func append(_ caption: AVFoundation.AVCaption) async throws
    #endif
    #if compiler(>=5.3) && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public func append(_ captionGroup: AVFoundation.AVCaptionGroup) async throws
    #endif
    public func appendImmediately(_ caption: AVFoundation.AVCaption) throws -> Swift.Bool
    public func appendImmediately(_ captionGroup: AVFoundation.AVCaptionGroup) throws -> Swift.Bool
    public func finish()
    @objc deinit
  }
}
@available(macOS 26.0, iOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVAssetWriter {
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputCaptionReceiver(for input: AVFoundation.AVAssetWriterInput) -> sending AVFoundation.AVAssetWriterInput.CaptionReceiver
  #else
  public func inputCaptionReceiver(for input: AVFoundation.AVAssetWriterInput) -> AVFoundation.AVAssetWriterInput.CaptionReceiver
  #endif
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputCaptionReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput) -> sending (AVFoundation.AVAssetWriterInput.CaptionReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #else
  public func inputCaptionReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput) -> (AVFoundation.AVAssetWriterInput.CaptionReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #endif
}
extension Foundation.NSNotification.Name {
  @available(macOS, introduced: 10.7, deprecated: 15.0, renamed: "AVCaptureSession.runtimeErrorNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureSession.runtimeErrorNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureSession.runtimeErrorNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureSession.runtimeErrorNotification")
  @available(visionOS, introduced: 1.0, deprecated: 2.0, renamed: "AVCaptureSession.runtimeErrorNotification")
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureSessionRuntimeError: Foundation.NSNotification.Name {
    get {
		AVCaptureSession.runtimeErrorNotification
	}
  }
  @available(macOS, introduced: 10.7, deprecated: 15.0, renamed: "AVCaptureSession.didStartRunningNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureSession.didStartRunningNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureSession.didStartRunningNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureSession.didStartRunningNotification")
  @available(visionOS, introduced: 1.0, deprecated: 2.0, renamed: "AVCaptureSession.didStartRunningNotification")
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureSessionDidStartRunning: Foundation.NSNotification.Name {
    get {
		AVCaptureSession.didStartRunningNotification
	}
  }
  @available(macOS, introduced: 10.7, deprecated: 15.0, renamed: "AVCaptureSession.didStopRunningNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureSession.didStopRunningNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureSession.didStopRunningNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureSession.didStopRunningNotification")
  @available(visionOS, introduced: 1.0, deprecated: 2.0, renamed: "AVCaptureSession.didStopRunningNotification")
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureSessionDidStopRunning: Foundation.NSNotification.Name {
    get {
		AVCaptureSession.didStopRunningNotification
	}
  }
  @available(macOS, introduced: 10.14, deprecated: 15.0, renamed: "AVCaptureSession.wasInterruptedNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureSession.wasInterruptedNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureSession.wasInterruptedNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureSession.wasInterruptedNotification")
  @available(visionOS, introduced: 1.0, deprecated: 2.0, renamed: "AVCaptureSession.wasInterruptedNotification")
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureSessionWasInterrupted: Foundation.NSNotification.Name {
    get {
		AVCaptureSession.wasInterruptedNotification
	}
  }
  @available(macOS, introduced: 10.14, deprecated: 15.0, renamed: "AVCaptureSession.interruptionEndedNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureSession.interruptionEndedNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureSession.interruptionEndedNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureSession.interruptionEndedNotification")
  @available(visionOS, introduced: 1.0, deprecated: 2.0, renamed: "AVCaptureSession.interruptionEndedNotification")
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureSessionInterruptionEnded: Foundation.NSNotification.Name {
    get {
		AVCaptureSession.interruptionEndedNotification
	}
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
public struct AVSpatialVideoConfiguration : Swift.Sendable {
  public var cameraCalibrationDataLensCollection: CoreMedia.CMFormatDescription.Extensions.Value.CameraCalibrationDataLensCollection?
  public var horizontalFieldOfView: Swift.UInt32?
  public var cameraSystemBaseline: Swift.UInt32?
  public var disparityAdjustment: Swift.Int32?
  public init()
  public init(formatDescription: CoreMedia.CMFormatDescription)
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVSpatialVideoConfiguration {
  public static var nonSpatial: AVFoundation.AVSpatialVideoConfiguration {
    get
  }
}
extension AVFoundation.AVAsynchronousKeyValueLoading {
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  public func status<T>(of property: AVFoundation.AVAsyncProperty<Self, T>) -> AVFoundation.AVAsyncProperty<Self, T>.Status
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd__AC15AVAsyncPropertyCyxqd__GYaKlF")
  internal func __loadForABI<T>(_ property: AVFoundation.AVAsyncProperty<Self, T>) async throws -> T
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @backDeployed(before: macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0)
  public func load<T>(_ property: AVFoundation.AVAsyncProperty<Self, T>, isolation: isolated (any _Concurrency.Actor)? = #isolation) async throws -> T {
		await loadValues(forKeys: [property.backDeployedKey])
		let status = try value(of: property)
		return status
	}
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @backDeployed(before: macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0)
  public func load<A, B, each C>(_ firstProperty: AVFoundation.AVAsyncProperty<Self, A>, _ secondProperty: AVFoundation.AVAsyncProperty<Self, B>, _ properties: repeat AVFoundation.AVAsyncProperty<Self, each C>, isolation: isolated (any _Concurrency.Actor)? = #isolation) async throws -> (A, B, repeat each C) {
		var stringKeys: [String] = [firstProperty.backDeployedKey, secondProperty.backDeployedKey]
		for p in repeat each properties {
			stringKeys.append(p.backDeployedKey)
		}
		await loadValues(forKeys: stringKeys)
		let firstStatus = try value(of: firstProperty)
		let secondStatus = try value(of: secondProperty)
		let statuses = (firstStatus, secondStatus, repeat try value(of: each properties))
		return statuses
	}
  #endif
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @backDeployed(before: macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0)
  @usableFromInline
  internal func value<T>(of loadedProperty: AVFoundation.AVAsyncProperty<Self, T>) throws -> T {
		let status = status(of: loadedProperty)
		switch status {
		case .loaded(let value):
			return value
		case .failed(let error):
			throw error
		default:
			fatalError("Unexpected status (\(status))")
		}
	}
}
@_hasMissingDesignatedInitializers @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
public class AVAnyAsyncProperty : Swift.CustomStringConvertible, @unchecked Swift.Sendable {
  public var description: Swift.String {
    get
  }
  @objc deinit
}
@_hasMissingDesignatedInitializers @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
public class AVPartialAsyncProperty<Root> : AVFoundation.AVAnyAsyncProperty {
  @usableFromInline
  final internal let key: Swift.String
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
  @usableFromInline
  internal var usableFromInlineKey: Swift.String {
    get
  }
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @backDeployed(before: macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0)
  @usableFromInline
  final internal var keyFromDescription: Swift.String {
    get {
		guard let keySubstring = description.split(separator: ".").last else {
			fatalError("Could not extract property name from async property description (\(description))")
		}
		return String(keySubstring)
	}
  }
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @backDeployed(before: macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0)
  @usableFromInline
  final internal var backDeployedKey: Swift.String {
    get {
		if #available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *) {
			return usableFromInlineKey
		} else {
			return keyFromDescription
		}
	}
  }
  override public var description: Swift.String {
    get
  }
  @objc deinit
}
@_hasMissingDesignatedInitializers @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
public class AVAsyncProperty<Root, Value> : AVFoundation.AVPartialAsyncProperty<Root> {
  @objc deinit
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAsyncProperty {
  @frozen public enum Status {
    case notYetLoaded
    case loading
    case loaded(Value)
    case failed(Foundation.NSError)
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAsyncProperty.Status : Swift.Equatable where Value : Swift.Equatable {
  public static func == (lhs: AVFoundation.AVAsyncProperty<Root, Value>.Status, rhs: AVFoundation.AVAsyncProperty<Root, Value>.Status) -> Swift.Bool
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAsyncProperty.Status : Swift.Sendable where Value : Swift.Sendable {
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAsyncProperty.Status : Swift.CustomStringConvertible {
  public var description: Swift.String {
    get
  }
}
extension AVFoundation.AVAsynchronousKeyValueLoading {
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd___qd_0_tAC15AVAsyncPropertyCyxqd__G_AFyxqd_0_GtYaKr0_lF")
  internal func __loadForABI<A, B>(_ propertyA: AVFoundation.AVAsyncProperty<Self, A>, _ propertyB: AVFoundation.AVAsyncProperty<Self, B>) async throws -> (A, B)
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd___qd_0_qd_1_tAC15AVAsyncPropertyCyxqd__G_AFyxqd_0_GAFyxqd_1_GtYaKr1_lF")
  internal func __loadForABI<A, B, C>(_ propertyA: AVFoundation.AVAsyncProperty<Self, A>, _ propertyB: AVFoundation.AVAsyncProperty<Self, B>, _ propertyC: AVFoundation.AVAsyncProperty<Self, C>) async throws -> (A, B, C)
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd___qd_0_qd_1_qd_2_tAC15AVAsyncPropertyCyxqd__G_AFyxqd_0_GAFyxqd_1_GAFyxqd_2_GtYaKr2_lF")
  internal func __loadForABI<A, B, C, D>(_ propertyA: AVFoundation.AVAsyncProperty<Self, A>, _ propertyB: AVFoundation.AVAsyncProperty<Self, B>, _ propertyC: AVFoundation.AVAsyncProperty<Self, C>, _ propertyD: AVFoundation.AVAsyncProperty<Self, D>) async throws -> (A, B, C, D)
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd___qd_0_qd_1_qd_2_qd_3_tAC15AVAsyncPropertyCyxqd__G_AFyxqd_0_GAFyxqd_1_GAFyxqd_2_GAFyxqd_3_GtYaKr3_lF")
  internal func __loadForABI<A, B, C, D, E>(_ propertyA: AVFoundation.AVAsyncProperty<Self, A>, _ propertyB: AVFoundation.AVAsyncProperty<Self, B>, _ propertyC: AVFoundation.AVAsyncProperty<Self, C>, _ propertyD: AVFoundation.AVAsyncProperty<Self, D>, _ propertyE: AVFoundation.AVAsyncProperty<Self, E>) async throws -> (A, B, C, D, E)
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd___qd_0_qd_1_qd_2_qd_3_qd_4_tAC15AVAsyncPropertyCyxqd__G_AFyxqd_0_GAFyxqd_1_GAFyxqd_2_GAFyxqd_3_GAFyxqd_4_GtYaKr4_lF")
  internal func __loadForABI<A, B, C, D, E, F>(_ propertyA: AVFoundation.AVAsyncProperty<Self, A>, _ propertyB: AVFoundation.AVAsyncProperty<Self, B>, _ propertyC: AVFoundation.AVAsyncProperty<Self, C>, _ propertyD: AVFoundation.AVAsyncProperty<Self, D>, _ propertyE: AVFoundation.AVAsyncProperty<Self, E>, _ propertyF: AVFoundation.AVAsyncProperty<Self, F>) async throws -> (A, B, C, D, E, F)
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd___qd_0_qd_1_qd_2_qd_3_qd_4_qd_5_tAC15AVAsyncPropertyCyxqd__G_AFyxqd_0_GAFyxqd_1_GAFyxqd_2_GAFyxqd_3_GAFyxqd_4_GAFyxqd_5_GtYaKr5_lF")
  internal func __loadForABI<A, B, C, D, E, F, G>(_ propertyA: AVFoundation.AVAsyncProperty<Self, A>, _ propertyB: AVFoundation.AVAsyncProperty<Self, B>, _ propertyC: AVFoundation.AVAsyncProperty<Self, C>, _ propertyD: AVFoundation.AVAsyncProperty<Self, D>, _ propertyE: AVFoundation.AVAsyncProperty<Self, E>, _ propertyF: AVFoundation.AVAsyncProperty<Self, F>, _ propertyG: AVFoundation.AVAsyncProperty<Self, G>) async throws -> (A, B, C, D, E, F, G)
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @usableFromInline
  @_silgen_name("$sSo29AVAsynchronousKeyValueLoadingP12AVFoundationE4loadyqd___qd_0_qd_1_qd_2_qd_3_qd_4_qd_5_qd_6_tAC15AVAsyncPropertyCyxqd__G_AFyxqd_0_GAFyxqd_1_GAFyxqd_2_GAFyxqd_3_GAFyxqd_4_GAFyxqd_5_GAFyxqd_6_GtYaKr6_lF")
  internal func __loadForABI<A, B, C, D, E, F, G, H>(_ propertyA: AVFoundation.AVAsyncProperty<Self, A>, _ propertyB: AVFoundation.AVAsyncProperty<Self, B>, _ propertyC: AVFoundation.AVAsyncProperty<Self, C>, _ propertyD: AVFoundation.AVAsyncProperty<Self, D>, _ propertyE: AVFoundation.AVAsyncProperty<Self, E>, _ propertyF: AVFoundation.AVAsyncProperty<Self, F>, _ propertyG: AVFoundation.AVAsyncProperty<Self, G>, _ propertyH: AVFoundation.AVAsyncProperty<Self, H>) async throws -> (A, B, C, D, E, F, G, H)
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriterInput {
  @_hasMissingDesignatedInitializers public class SampleBufferReceiver {
    #if compiler(>=5.3) && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public func append(_ sampleBuffer: CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>) async throws
    #endif
    public func appendImmediately(_ sampleBuffer: CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>) throws -> Swift.Bool
    public func finish()
    @objc deinit
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriter {
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputReceiver(for input: AVFoundation.AVAssetWriterInput) -> sending AVFoundation.AVAssetWriterInput.SampleBufferReceiver
  #else
  public func inputReceiver(for input: AVFoundation.AVAssetWriterInput) -> AVFoundation.AVAssetWriterInput.SampleBufferReceiver
  #endif
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput) -> sending (AVFoundation.AVAssetWriterInput.SampleBufferReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #else
  public func inputReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput) -> (AVFoundation.AVAssetWriterInput.SampleBufferReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #endif
}
@available(macOS 11.0, iOS 7.0, macCatalyst 14.0, tvOS 17.0, *)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVMetadataMachineReadableCodeObject {
  @nonobjc public var corners: [CoreFoundation.CGPoint] {
    get
  }
}
@available(macOS 26.0, iOS 26.0, watchOS 26.0, visionOS 26.0, *)
@available(tvOS, unavailable)
extension AVFoundation.AVMutableMovieTrack {
  public func append(_ sampleBuffer: CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>) throws -> (decodeTime: CoreMedia.CMTime, presentationTime: CoreMedia.CMTime)
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  public static var duration: AVFoundation.AVAsyncProperty<Root, CoreMedia.CMTime> {
    get
  }
  public static var preferredRate: AVFoundation.AVAsyncProperty<Root, Swift.Float> {
    get
  }
  public static var preferredVolume: AVFoundation.AVAsyncProperty<Root, Swift.Float> {
    get
  }
  public static var preferredTransform: AVFoundation.AVAsyncProperty<Root, CoreFoundation.CGAffineTransform> {
    get
  }
  public static var minimumTimeOffsetFromLive: AVFoundation.AVAsyncProperty<Root, CoreMedia.CMTime> {
    get
  }
  public static var providesPreciseDurationAndTiming: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVAssetTrack]> {
    get
  }
  public static var trackGroups: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVAssetTrackGroup]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  #if compiler(>=5.3) && $NonescapableTypes
  public static var creationDate: AVFoundation.AVAsyncProperty<Root, AVFoundation.AVMetadataItem?> {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static var lyrics: AVFoundation.AVAsyncProperty<Root, Swift.String?> {
    get
  }
  #endif
  public static var commonMetadata: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMetadataItem]> {
    get
  }
  public static var metadata: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMetadataItem]> {
    get
  }
  public static var availableMetadataFormats: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMetadataFormat]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  public static var availableChapterLocales: AVFoundation.AVAsyncProperty<Root, [Foundation.Locale]> {
    get
  }
}
extension AVFoundation.AVAsset {
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  public func loadChapterMetadataGroups(withTitleLocale locale: Foundation.Locale, containingItemsWithCommonKeys commonKeys: [AVFoundation.AVMetadataKey] = []) async throws -> [AVFoundation.AVTimedMetadataGroup]
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVURLAsset {
  public static var variants: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVAssetVariant]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  public static var availableMediaCharacteristicsWithMediaSelectionOptions: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMediaCharacteristic]> {
    get
  }
  public static var preferredMediaSelection: AVFoundation.AVAsyncProperty<Root, AVFoundation.AVMediaSelection> {
    get
  }
  public static var allMediaSelections: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMediaSelection]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  @available(macOS 12, iOS 15, tvOS 15, visionOS 1, *)
  @available(watchOS, unavailable)
  public static var hasProtectedContent: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  @available(macOS 12, iOS 15, tvOS 15, visionOS 1, *)
  @available(watchOS, unavailable)
  public static var canContainFragments: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  @available(macOS 12, iOS 15, tvOS 15, visionOS 1, *)
  @available(watchOS, unavailable)
  public static var containsFragments: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  public static var overallDurationHint: AVFoundation.AVAsyncProperty<Root, CoreMedia.CMTime> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAsset {
  public static var isPlayable: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  @available(macOS 12, iOS 15, tvOS 15, visionOS 1, *)
  @available(watchOS, unavailable)
  public static var isExportable: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  @available(macOS 12, iOS 15, tvOS 15, visionOS 1, *)
  @available(watchOS, unavailable)
  public static var isReadable: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  public static var isComposable: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  @available(iOS 15, tvOS 15, visionOS 1, *)
  @available(macOS, unavailable)
  @available(watchOS, unavailable)
  public static var isCompatibleWithSavedPhotosAlbum: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  @available(macOS 12, iOS 15, tvOS 15, visionOS 1, *)
  @available(watchOS, unavailable)
  public static var isCompatibleWithAirPlayVideo: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVPlayerItemVideoOutput {
  convenience public init(pixelBufferAttributes: CoreVideo.CVPixelBufferAttributes)
  #if compiler(>=5.3) && $NonescapableTypes
  public func pixelBufferAndDisplayTime(forItemTime itemTime: CoreMedia.CMTime) -> (pixelBuffer: CoreVideo.CVReadOnlyPixelBuffer?, itemTimeForDisplay: CoreMedia.CMTime)
  #endif
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetResourceLoader : @unchecked Swift.Sendable {
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetResourceLoadingRequest : @unchecked Swift.Sendable {
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetResourceLoadingRequestor : @unchecked Swift.Sendable {
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetResourceRenewalRequest : @unchecked Swift.Sendable {
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetResourceLoadingContentInformationRequest : @unchecked Swift.Sendable {
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetResourceLoadingDataRequest : @unchecked Swift.Sendable {
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
extension AVFoundation.AVPlayerItemTrack : Observation.Observable {
}
@available(macOS 12.0, iOS 18.0, macCatalyst 15.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVCaption {
  #if compiler(>=5.3) && $NonescapableTypes
  @nonobjc public func textColor(at index: Swift.String.Index) -> (CoreGraphics.CGColor?, Swift.Range<Swift.String.Index>)
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @nonobjc public func backgroundColor(at index: Swift.String.Index) -> (CoreGraphics.CGColor?, Swift.Range<Swift.String.Index>)
  #endif
  @nonobjc public func fontWeight(at index: Swift.String.Index) -> (AVFoundation.AVCaption.FontWeight, Swift.Range<Swift.String.Index>)
  @nonobjc public func fontStyle(at index: Swift.String.Index) -> (AVFoundation.AVCaption.FontStyle, Swift.Range<Swift.String.Index>)
  @nonobjc public func decoration(at index: Swift.String.Index) -> (AVFoundation.AVCaption.Decoration, Swift.Range<Swift.String.Index>)
  @nonobjc public func textCombine(at index: Swift.String.Index) -> (AVFoundation.AVCaption.TextCombine, Swift.Range<Swift.String.Index>)
  #if compiler(>=5.3) && $NonescapableTypes
  @nonobjc public func ruby(at index: Swift.String.Index) -> (AVFoundation.AVCaption.Ruby?, Swift.Range<Swift.String.Index>)
  #endif
}
@available(macOS 12.0, iOS 18.0, macCatalyst 15.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVMutableCaption {
  @nonobjc public func setTextColor(_ textColor: CoreGraphics.CGColor, in range: Foundation.NSRange)
  @nonobjc public func setBackgroundColor(_ backgroundColor: CoreGraphics.CGColor, in range: Foundation.NSRange)
  @nonobjc public func setFontWeight(_ fontWeight: AVFoundation.AVCaption.FontWeight, in range: Foundation.NSRange)
  @nonobjc public func setFontStyle(_ fontStyle: AVFoundation.AVCaption.FontStyle, in range: Foundation.NSRange)
  @nonobjc public func setDecoration(_ decoration: AVFoundation.AVCaption.Decoration, in range: Foundation.NSRange)
  @nonobjc public func setTextCombine(_ textCombine: AVFoundation.AVCaption.TextCombine, in range: Foundation.NSRange)
  @nonobjc public func setRuby(_ rubyText: AVFoundation.AVCaption.Ruby, in range: Foundation.NSRange)
  @nonobjc public func removeTextColor(in range: Foundation.NSRange)
  @nonobjc public func removeBackgroundColor(in range: Foundation.NSRange)
  @nonobjc public func removeFontWeight(in range: Foundation.NSRange)
  @nonobjc public func removeFontStyle(in range: Foundation.NSRange)
  @nonobjc public func removeDecoration(in range: Foundation.NSRange)
  @nonobjc public func removeTextCombine(in range: Foundation.NSRange)
  @nonobjc public func removeRuby(in range: Foundation.NSRange)
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2, *)
extension AVFoundation.AVMetricEventStreamPublisher {
  public func metrics<MetricEvent>(forType metricType: MetricEvent.Type) -> AVFoundation.AVMetrics<MetricEvent> where MetricEvent : AVFoundation.AVMetricEvent
  public func allMetrics() -> AVFoundation.AVMetrics<AVFoundation.AVMetricEvent>
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2, *)
public struct AVMetrics<MetricEvent> : _Concurrency.AsyncSequence, @unchecked Swift.Sendable where MetricEvent : AVFoundation.AVMetricEvent {
  public func makeAsyncIterator() -> AVFoundation.AVMetrics<MetricEvent>.AsyncIterator
  public typealias Element = MetricEvent
  public struct AsyncIterator : _Concurrency.AsyncIteratorProtocol {
    #if compiler(>=5.3) && $NonescapableTypes
    public mutating func next() async throws -> MetricEvent?
    #endif
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2, macOS 15, *)
    public typealias Element = MetricEvent
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2, macOS 15, *)
    @_implements(_Concurrency.AsyncIteratorProtocol, Failure) public typealias __AsyncIteratorProtocol_Failure = any Swift.Error
  }
  public func chronologicalMerge<OtherSecondMetric, each MetricEventPack>(with secondMetric: AVFoundation.AVMetrics<OtherSecondMetric>, _ metrics: repeat AVFoundation.AVMetrics<each MetricEventPack>) -> AVFoundation.AVMergedMetrics<MetricEvent, OtherSecondMetric, repeat each MetricEventPack> where OtherSecondMetric : AVFoundation.AVMetricEvent, repeat each MetricEventPack : AVFoundation.AVMetricEvent
  @available(iOS 18, tvOS 18, watchOS 11, visionOS 2, macOS 15, *)
  @_implements(_Concurrency.AsyncSequence, Failure) public typealias __AsyncSequence_Failure = any Swift.Error
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2, *)
public struct AVMergedMetrics<MetricEvent1, MetricEvent2, each MetricEventPack> : _Concurrency.AsyncSequence where MetricEvent1 : AVFoundation.AVMetricEvent, MetricEvent2 : AVFoundation.AVMetricEvent, repeat each MetricEventPack : AVFoundation.AVMetricEvent {
  public func makeAsyncIterator() -> AVFoundation.AVMergedMetrics<MetricEvent1, MetricEvent2, repeat each MetricEventPack>.AsyncIterator
  public typealias Element = (AVFoundation.AVMetricEvent, any AVFoundation.AVMetricEventStreamPublisher)
  public struct AsyncIterator : _Concurrency.AsyncIteratorProtocol {
    #if compiler(>=5.3) && $NonescapableTypes
    public mutating func next() async throws -> (AVFoundation.AVMetricEvent, any AVFoundation.AVMetricEventStreamPublisher)?
    #endif
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2, macOS 15, *)
    public typealias Element = (AVFoundation.AVMetricEvent, any AVFoundation.AVMetricEventStreamPublisher)
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2, macOS 15, *)
    @_implements(_Concurrency.AsyncIteratorProtocol, Failure) public typealias __AsyncIteratorProtocol_Failure = any Swift.Error
  }
  @available(iOS 18, tvOS 18, watchOS 11, visionOS 2, macOS 15, *)
  @_implements(_Concurrency.AsyncSequence, Failure) public typealias __AsyncSequence_Failure = any Swift.Error
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2, *)
extension AVFoundation.AVMetricPlayerItemLikelyToKeepUpEvent {
  @nonobjc public var loadedTimeRanges: [CoreMedia.CMTimeRange] {
    get
  }
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2, *)
extension AVFoundation.AVMetricPlayerItemVariantSwitchEvent {
  @nonobjc public var loadedTimeRanges: [CoreMedia.CMTimeRange] {
    get
  }
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2, *)
extension AVFoundation.AVMetricPlayerItemVariantSwitchStartEvent {
  @nonobjc public var loadedTimeRanges: [CoreMedia.CMTimeRange] {
    get
  }
}
@available(macOS 12.0, iOS 15.0, tvOS 15.0, visionOS 1, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoComposition {
  @objc(_sourceSampleDataTrackIDs) dynamic public var sourceSampleDataTrackIDs: [CoreMedia.CMPersistentTrackID] {
    @objc get
  }
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
  @available(watchOS, unavailable)
  public var outputBufferDescription: [[CoreMedia.CMTag]]? {
    get
  }
  #endif
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
  @available(watchOS, unavailable)
  public var spatialVideoConfigurations: [AVFoundation.AVSpatialVideoConfiguration] {
    get
  }
}
@available(macOS 12.0, iOS 15.0, tvOS 15.0, visionOS 1, *)
@available(watchOS, unavailable)
extension AVFoundation.AVMutableVideoComposition {
  @objc(_sourceSampleDataTrackIDs) override dynamic public var sourceSampleDataTrackIDs: [CoreMedia.CMPersistentTrackID] {
    @objc get
    @objc set
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
public struct AVCIImageFilteringParameters {
  public let sourceImage: CoreImage.CIImage
  public let compositionTime: CoreMedia.CMTime
  public let renderSize: CoreFoundation.CGSize
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
public struct AVCIImageFilteringResult {
  public let resultImage: CoreImage.CIImage
  public let ciContext: CoreImage.CIContext?
  #if compiler(>=5.3) && $NonescapableTypes
  public init(resultImage: CoreImage.CIImage, ciContext: CoreImage.CIContext? = nil)
  #endif
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoComposition : @unchecked Swift.Sendable {
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoComposition {
  #if compiler(>=5.3) && $AsyncExecutionBehaviorAttributes
  nonisolated(nonsending) convenience public init(applyingFiltersTo asset: AVFoundation.AVAsset, applier: @escaping @Sendable (AVFoundation.AVCIImageFilteringParameters) async throws -> AVFoundation.AVCIImageFilteringResult) async throws
  #endif
  public struct Configuration : Swift.Sendable {
    #if compiler(>=5.3) && $NonescapableTypes
    public var animationTool: AVFoundation.AVVideoCompositionCoreAnimationTool? {
      get
      set
    }
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public var colorPrimaries: Swift.String? {
      get
      set
    }
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public var colorTransferFunction: Swift.String? {
      get
      set
    }
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public var colorYCbCrMatrix: Swift.String? {
      get
      set
    }
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public var customVideoCompositorClass: (any AVFoundation.AVVideoCompositing.Type)? {
      get
      set
    }
    #endif
    public var frameDuration: CoreMedia.CMTime {
      get
      set
    }
    public var instructions: [any AVFoundation.AVVideoCompositionInstructionProtocol] {
      get
      set
    }
    #if compiler(>=5.3) && $NonescapableTypes
    public var outputBufferDescription: [[CoreMedia.CMTag]]? {
      get
      set
    }
    #endif
    public var spatialVideoConfigurations: [AVFoundation.AVSpatialVideoConfiguration] {
      get
      set
    }
    @available(tvOS, unavailable)
    public var perFrameHDRDisplayMetadataPolicy: AVFoundation.AVVideoComposition.PerFrameHDRDisplayMetadataPolicy {
      get
      set
    }
    public var renderScale: Swift.Float {
      get
      set
    }
    public var renderSize: CoreFoundation.CGSize {
      get
      set
    }
    public var sourceSampleDataTrackIDs: [CoreMedia.CMPersistentTrackID] {
      get
      set
    }
    public var sourceTrackIDForFrameTiming: CoreMedia.CMPersistentTrackID {
      get
      set
    }
    #if compiler(>=5.3) && $NonescapableTypes && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public init(for asset: AVFoundation.AVAsset, prototypeInstruction: AVFoundation.AVVideoCompositionInstruction? = nil) async throws
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    @available(tvOS, unavailable)
    public init(animationTool: AVFoundation.AVVideoCompositionCoreAnimationTool? = nil, colorPrimaries: Swift.String? = nil, colorTransferFunction: Swift.String? = nil, colorYCbCrMatrix: Swift.String? = nil, customVideoCompositorClass: (any AVFoundation.AVVideoCompositing.Type)? = nil, frameDuration: CoreMedia.CMTime = CMTime.zero, instructions: [any AVFoundation.AVVideoCompositionInstructionProtocol] = [any AVVideoCompositionInstructionProtocol](), outputBufferDescription: [[CoreMedia.CMTag]]? = nil, perFrameHDRDisplayMetadataPolicy: AVFoundation.AVVideoComposition.PerFrameHDRDisplayMetadataPolicy = .propagate, renderScale: Swift.Float = 1.0, renderSize: CoreFoundation.CGSize = .zero, sourceSampleDataTrackIDs: [CoreMedia.CMPersistentTrackID] = [CMPersistentTrackID](), sourceTrackIDForFrameTiming: Swift.Int32 = CMPersistentTrackID.zero, spatialVideoConfigurations: [AVFoundation.AVSpatialVideoConfiguration] = [])
    #endif
  }
  convenience public init(configuration: AVFoundation.AVVideoComposition.Configuration)
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoCompositionInstruction {
  public struct Configuration : Swift.Sendable {
    public var backgroundColor: CoreGraphics.CGColor?
    public var enablePostProcessing: Swift.Bool
    public var layerInstructions: [AVFoundation.AVVideoCompositionLayerInstruction] {
      get
      set
    }
    public var requiredSourceSampleDataTrackIDs: [CoreMedia.CMPersistentTrackID]
    public var timeRange: CoreMedia.CMTimeRange
    #if compiler(>=5.3) && $NonescapableTypes
    public init(backgroundColor: CoreGraphics.CGColor? = nil, enablePostProcessing: Swift.Bool = true, layerInstructions: [AVFoundation.AVVideoCompositionLayerInstruction] = [], requiredSourceSampleDataTrackIDs: [CoreMedia.CMPersistentTrackID] = [], timeRange: CoreMedia.CMTimeRange = .zero)
    #endif
  }
  convenience public init(configuration: AVFoundation.AVVideoCompositionInstruction.Configuration)
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoCompositionLayerInstruction {
  public struct Configuration : Swift.Sendable {
    public var trackID: CoreMedia.CMPersistentTrackID {
      get
      set
    }
    public init(trackID: CoreMedia.CMPersistentTrackID = .zero)
    public init(assetTrack: AVFoundation.AVAssetTrack)
    #if compiler(>=5.3) && $NonescapableTypes
    public func cropRectangleRamp(at time: CoreMedia.CMTime) -> AVFoundation.AVVideoCompositionLayerInstruction.CropRectangleRamp?
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public func opacityRamp(at time: CoreMedia.CMTime) -> AVFoundation.AVVideoCompositionLayerInstruction.OpacityRamp?
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public func transformRamp(at time: CoreMedia.CMTime) -> AVFoundation.AVVideoCompositionLayerInstruction.TransformRamp?
    #endif
    public mutating func setOpacity(_ opacity: Swift.Float, at time: CoreMedia.CMTime)
    public mutating func addOpacityRamp(_ ramp: AVFoundation.AVVideoCompositionLayerInstruction.OpacityRamp)
    public mutating func setTransform(_ transform: CoreFoundation.CGAffineTransform, at time: CoreMedia.CMTime)
    public mutating func addTransformRamp(_ ramp: AVFoundation.AVVideoCompositionLayerInstruction.TransformRamp)
    public mutating func setCropRectangle(_ rect: CoreFoundation.CGRect, at time: CoreMedia.CMTime)
    public mutating func addCropRectangleRamp(_ ramp: AVFoundation.AVVideoCompositionLayerInstruction.CropRectangleRamp)
  }
  convenience public init(configuration: AVFoundation.AVVideoCompositionLayerInstruction.Configuration)
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoCompositionLayerInstruction {
  public struct CropRectangleRamp : Swift.Equatable, Swift.Sendable {
    public var timeRange: CoreMedia.CMTimeRange
    public var start: CoreFoundation.CGRect
    public var end: CoreFoundation.CGRect
    public init(timeRange: CoreMedia.CMTimeRange, start: CoreFoundation.CGRect, end: CoreFoundation.CGRect)
    public static func == (a: AVFoundation.AVVideoCompositionLayerInstruction.CropRectangleRamp, b: AVFoundation.AVVideoCompositionLayerInstruction.CropRectangleRamp) -> Swift.Bool
  }
  public struct OpacityRamp : Swift.Equatable, Swift.Sendable {
    public var timeRange: CoreMedia.CMTimeRange
    public var start: Swift.Float
    public var end: Swift.Float
    public init(timeRange: CoreMedia.CMTimeRange, start: Swift.Float, end: Swift.Float)
    public static func == (a: AVFoundation.AVVideoCompositionLayerInstruction.OpacityRamp, b: AVFoundation.AVVideoCompositionLayerInstruction.OpacityRamp) -> Swift.Bool
  }
  public struct TransformRamp : Swift.Equatable, Swift.Sendable {
    public var timeRange: CoreMedia.CMTimeRange
    public var start: CoreFoundation.CGAffineTransform
    public var end: CoreFoundation.CGAffineTransform
    public init(timeRange: CoreMedia.CMTimeRange, start: CoreFoundation.CGAffineTransform, end: CoreFoundation.CGAffineTransform)
    public static func == (a: AVFoundation.AVVideoCompositionLayerInstruction.TransformRamp, b: AVFoundation.AVVideoCompositionLayerInstruction.TransformRamp) -> Swift.Bool
  }
  #if compiler(>=5.3) && $NonescapableTypes
  public func cropRectangleRamp(at time: CoreMedia.CMTime) -> AVFoundation.AVVideoCompositionLayerInstruction.CropRectangleRamp?
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public func opacityRamp(at time: CoreMedia.CMTime) -> AVFoundation.AVVideoCompositionLayerInstruction.OpacityRamp?
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public func transformRamp(at time: CoreMedia.CMTime) -> AVFoundation.AVVideoCompositionLayerInstruction.TransformRamp?
  #endif
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoCompositionCoreAnimationTool {
  public struct Configuration {
    public var layers: [QuartzCore.CALayer]
    public var containingLayer: QuartzCore.CALayer
    public init(postProcessingAsVideoLayers layers: [QuartzCore.CALayer], containingLayer: QuartzCore.CALayer)
    public init(postProcessingAsVideoLayer layer: QuartzCore.CALayer, containingLayer: QuartzCore.CALayer)
  }
  #if compiler(>=5.3) && $SendingArgsAndResults
  convenience public init(configuration: sending AVFoundation.AVVideoCompositionCoreAnimationTool.Configuration)
  #else
  convenience public init(configuration: __owned AVFoundation.AVVideoCompositionCoreAnimationTool.Configuration)
  #endif
}
@available(macOS, introduced: 14, deprecated: 26.0, message: "Use AVAssetWriterInput.TaggedPixelBufferGroupReceiver.append(_:with:isolation:) instead")
@available(iOS, introduced: 17, deprecated: 26.0, message: "Use AVAssetWriterInput.TaggedPixelBufferGroupReceiver.append(_:with:isolation:) instead")
@available(visionOS, introduced: 1, deprecated: 26.0, message: "Use AVAssetWriterInput.TaggedPixelBufferGroupReceiver.append(_:with:isolation:) instead")
@available(tvOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriterInputTaggedPixelBufferGroupAdaptor {
  public func appendTaggedBuffers(_ taggedBuffers: [CoreMedia.CMTaggedBuffer], withPresentationTime: CoreMedia.CMTime) -> Swift.Bool
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriterInput {
  @_hasMissingDesignatedInitializers public class MultiPassController {
    #if compiler(>=5.3) && $NonescapableTypes
    public var passDescriptions: (some _Concurrency.AsyncSequence<AVFoundation.AVAssetWriterInputPassDescription, Swift.Never>)? {
      get
    }
    #endif
    @objc deinit
  }
}
@available(macOS 15.0, iOS 18.0, macCatalyst 18.0, tvOS 18.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureSlider {
  @nonobjc public var prominentValues: [Swift.Float] {
    get
    set
  }
  @nonobjc convenience public init(_ localizedTitle: Swift.String, symbolName: Swift.String, in range: Swift.ClosedRange<Swift.Float>)
  @nonobjc convenience public init(_ localizedTitle: Swift.String, symbolName: Swift.String, in range: Swift.ClosedRange<Swift.Float>, step: Swift.Float)
  @nonobjc convenience public init(_ localizedTitle: Swift.String, symbolName: Swift.String, values: [Swift.Float])
  @nonobjc public func setActionQueue(_ actionQueue: Dispatch.DispatchQueue, action: @escaping (Swift.Float) -> ())
}
@available(macOS 12.0, iOS 15.0, tvOS 15.0, visionOS 1, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAsynchronousVideoCompositionRequest {
  @nonobjc public var sourceSampleDataTrackIDs: [CoreMedia.CMPersistentTrackID] {
    get
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAsynchronousVideoCompositionRequest {
  #if compiler(>=5.3) && $NonescapableTypes
  public func sourceTaggedDynamicBuffers(byTrackID trackID: CoreMedia.CMPersistentTrackID) -> [CoreMedia.CMTaggedDynamicBuffer]?
  #endif
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAsynchronousVideoCompositionRequest {
  #if compiler(>=5.3) && $NonescapableTypes
  public func sourceReadOnlyPixelBuffer(byTrackID trackID: CoreMedia.CMPersistentTrackID) -> CoreVideo.CVReadOnlyPixelBuffer?
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
  @available(watchOS, unavailable)
  public func sourceReadySampleBuffer(byTrackID trackID: CoreMedia.CMPersistentTrackID) -> CoreMedia.CMReadySampleBuffer<CoreMedia.CMSampleBuffer.DynamicContent>?
  #endif
  public func finish(withComposedPixelBuffer readOnlyPixelBuffer: CoreVideo.CVReadOnlyPixelBuffer)
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
  @available(watchOS, unavailable)
  public func finish(withComposedTaggedBuffers taggedBuffers: [CoreMedia.CMTaggedDynamicBuffer])
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
  @available(watchOS, unavailable)
  public func attach(_ spatialVideoConfiguration: AVFoundation.AVSpatialVideoConfiguration, to pixelBuffer: inout CoreVideo.CVMutablePixelBuffer) throws
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVVideoCompositionRenderContext {
  public func makeMutablePixelBuffer() throws -> CoreVideo.CVMutablePixelBuffer
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
extension AVFoundation.AVPlayer : Observation.Observable {
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAssetVariant {
  #if compiler(>=5.3) && $NonescapableTypes
  @nonobjc public var peakBitRate: Swift.Double? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @nonobjc public var averageBitRate: Swift.Double? {
    get
  }
  #endif
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAssetVariant.VideoAttributes {
  #if compiler(>=5.3) && $NonescapableTypes
  @nonobjc public var nominalFrameRate: Swift.Double? {
    get
  }
  #endif
  @nonobjc public var codecTypes: [CoreMedia.CMVideoCodecType] {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAssetVariant.AudioAttributes {
  @nonobjc public var formatIDs: [CoreAudioTypes.AudioFormatID] {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVAssetVariant.AudioAttributes.RenditionSpecificAttributes {
  #if compiler(>=5.3) && $NonescapableTypes
  @nonobjc public var channelCount: Swift.Int? {
    get
  }
  #endif
}
@available(macOS 13.0, iOS 16.0, tvOS 16.0, watchOS 9.0, visionOS 1.0, *)
extension AVFoundation.AVAssetVariant.VideoAttributes : @unchecked Swift.Sendable {
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriterInput {
  @_hasMissingDesignatedInitializers public class PixelBufferReceiver {
    #if compiler(>=5.3) && $NonescapableTypes
    public var sourcePixelBufferAttributes: CoreVideo.CVPixelBufferCreationAttributes? {
      get
    }
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public var pixelBufferPool: CoreVideo.CVMutablePixelBuffer.Pool? {
      get
    }
    #endif
    #if compiler(>=5.3) && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public func append(_ pixelBuffer: CoreVideo.CVReadOnlyPixelBuffer, with presentationTime: CoreMedia.CMTime) async throws
    #endif
    public func appendImmediately(_ pixelBuffer: CoreVideo.CVReadOnlyPixelBuffer, with presentationTime: CoreMedia.CMTime) throws -> Swift.Bool
    public func finish()
    @objc deinit
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriter {
  #if compiler(>=5.3) && $NonescapableTypes
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputPixelBufferReceiver(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> sending AVFoundation.AVAssetWriterInput.PixelBufferReceiver
  #else
  public func inputPixelBufferReceiver(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> AVFoundation.AVAssetWriterInput.PixelBufferReceiver
  #endif
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputPixelBufferReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> sending (AVFoundation.AVAssetWriterInput.PixelBufferReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #else
  public func inputPixelBufferReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> (AVFoundation.AVAssetWriterInput.PixelBufferReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #endif
  #endif
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2.0, *)
extension AVFoundation.AVPlayerItemSegment {
  @available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2.0, *)
  @nonobjc public var loadedTimeRanges: [CoreMedia.CMTimeRange] {
    get
  }
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2.0, *)
extension AVFoundation.AVPlayerItemIntegratedTimelineSnapshot {
  @available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2.0, *)
  public func segmentAndOffsetIntoSegment(forTimelineTime: CoreMedia.CMTime) -> (AVFoundation.AVPlayerItemSegment, CoreMedia.CMTime)
}
@available(macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2.0, *)
extension AVFoundation.AVPlayerItemIntegratedTimeline {
  public struct PeriodicTimes : _Concurrency.AsyncSequence, Swift.Sendable {
    public typealias Element = CoreMedia.CMTime
    public func makeAsyncIterator() -> AVFoundation.AVPlayerItemIntegratedTimeline.PeriodicTimes.Iterator
    public struct Iterator : _Concurrency.AsyncIteratorProtocol {
      #if compiler(>=5.3) && $NonescapableTypes
      public mutating func next() async -> AVFoundation.AVPlayerItemIntegratedTimeline.PeriodicTimes.Element?
      #endif
      @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
      public typealias Element = AVFoundation.AVPlayerItemIntegratedTimeline.PeriodicTimes.Element
      @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
      @_implements(_Concurrency.AsyncIteratorProtocol, Failure) public typealias __AsyncIteratorProtocol_Failure = Swift.Never
    }
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
    public typealias AsyncIterator = AVFoundation.AVPlayerItemIntegratedTimeline.PeriodicTimes.Iterator
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
    @_implements(_Concurrency.AsyncSequence, Failure) public typealias __AsyncSequence_Failure = Swift.Never
  }
  public struct BoundaryTimes : _Concurrency.AsyncSequence, Swift.Sendable {
    public typealias Element = CoreMedia.CMTime
    public func makeAsyncIterator() -> AVFoundation.AVPlayerItemIntegratedTimeline.BoundaryTimes.Iterator
    public struct Iterator : _Concurrency.AsyncIteratorProtocol {
      #if compiler(>=5.3) && $NonescapableTypes
      public mutating func next() async -> AVFoundation.AVPlayerItemIntegratedTimeline.BoundaryTimes.Element?
      #endif
      @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
      public typealias Element = AVFoundation.AVPlayerItemIntegratedTimeline.BoundaryTimes.Element
      @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
      @_implements(_Concurrency.AsyncIteratorProtocol, Failure) public typealias __AsyncIteratorProtocol_Failure = Swift.Never
    }
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
    public typealias AsyncIterator = AVFoundation.AVPlayerItemIntegratedTimeline.BoundaryTimes.Iterator
    @available(iOS 18, tvOS 18, watchOS 11, visionOS 2.0, macOS 15, *)
    @_implements(_Concurrency.AsyncSequence, Failure) public typealias __AsyncSequence_Failure = Swift.Never
  }
  public func periodicTimes(forInterval: CoreMedia.CMTime) -> AVFoundation.AVPlayerItemIntegratedTimeline.PeriodicTimes
  public func boundaryTimes(for segment: AVFoundation.AVPlayerItemSegment, offsetsIntoSegment: [CoreMedia.CMTime]) -> AVFoundation.AVPlayerItemIntegratedTimeline.BoundaryTimes
}
@available(iOS 11.0, macCatalyst 18.0, tvOS 17.0, *)
@available(macOS, unavailable)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureSynchronizedDataCollection : Swift.Sequence {
  public func makeIterator() -> AVFoundation.AVCaptureSynchronizedDataCollection.Iterator
  public struct Iterator : Swift.IteratorProtocol {
    #if compiler(>=5.3) && $NonescapableTypes
    public mutating func next() -> AVFoundation.AVCaptureSynchronizedData?
    #endif
    @available(iOS 11.0, tvOS 17.0, macCatalyst 18.0, *)
    @available(watchOS, unavailable)
    @available(visionOS, unavailable)
    @available(macOS, unavailable)
    public typealias Element = AVFoundation.AVCaptureSynchronizedData
  }
  @available(iOS 11.0, tvOS 17.0, macCatalyst 18.0, *)
  @available(watchOS, unavailable)
  @available(visionOS, unavailable)
  @available(macOS, unavailable)
  public typealias Element = AVFoundation.AVCaptureSynchronizedData
}
extension AVFoundation.AVPlayerItem {
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @_Concurrency.MainActor @preconcurrency convenience public init(asset: AVFoundation.AVAsset, automaticallyLoadedAssetKeys: [AVFoundation.AVPartialAsyncProperty<AVFoundation.AVAsset>] = [])
  @available(macOS 10.7, iOS 4.0, tvOS 9.0, watchOS 1.0, visionOS 1.0, *)
  @_alwaysEmitIntoClient nonisolated convenience public init(asset: any AVFoundation.AVAsset & Swift.Sendable) {
		self.init(asset: asset as AVAsset)
	}
  @available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
  @_alwaysEmitIntoClient nonisolated convenience public init(asset: any AVFoundation.AVAsset & Swift.Sendable, automaticallyLoadedAssetKeys: [AVFoundation.AVPartialAsyncProperty<AVFoundation.AVAsset>]) {
		self.init(asset:asset as AVAsset, automaticallyLoadedAssetKeys:automaticallyLoadedAssetKeys)
	}
  @available(macOS 13, iOS 16, tvOS 16, watchOS 9, visionOS 1, *)
  nonisolated public func seek(to date: Foundation.Date) async -> Swift.Bool
}
extension Foundation.NSNotification.Name {
  @available(macOS, introduced: 10.7, deprecated: 100000, message: "Use AVPlayerItem.timeJumpedNotification instead.")
  @available(iOS, introduced: 5.0, deprecated: 100000, message: "Use AVPlayerItem.timeJumpedNotification instead.")
  @available(tvOS, introduced: 9.0, deprecated: 100000, message: "Use AVPlayerItem.timeJumpedNotification instead.")
  @available(watchOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.timeJumpedNotification instead.")
  @available(visionOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.timeJumpedNotification instead.")
  @_alwaysEmitIntoClient public static var AVPlayerItemTimeJumped: Foundation.NSNotification.Name {
    get {
		Self("AVPlayerItemTimeJumpedNotification")
	}
  }
  @available(macOS, introduced: 10.9, deprecated: 100000, message: "Use AVPlayerItem.playbackStalledNotification instead.")
  @available(iOS, introduced: 6.0, deprecated: 100000, message: "Use AVPlayerItem.playbackStalledNotification instead.")
  @available(tvOS, introduced: 9.0, deprecated: 100000, message: "Use AVPlayerItem.playbackStalledNotification instead.")
  @available(watchOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.playbackStalledNotification instead.")
  @available(visionOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.playbackStalledNotification instead.")
  @_alwaysEmitIntoClient public static var AVPlayerItemPlaybackStalled: Foundation.NSNotification.Name {
    get {
        Self("AVPlayerItemPlaybackStalledNotification")
    }
  }
  @available(macOS, introduced: 10.9, deprecated: 100000, message: "Use AVPlayerItem.newErrorLogEntryNotification instead.")
  @available(iOS, introduced: 6.0, deprecated: 100000, message: "Use AVPlayerItem.newErrorLogEntryNotification instead.")
  @available(tvOS, introduced: 9.0, deprecated: 100000, message: "Use AVPlayerItem.newErrorLogEntryNotification instead.")
  @available(watchOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.newErrorLogEntryNotification instead.")
  @available(visionOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.newErrorLogEntryNotification instead.")
  @_alwaysEmitIntoClient public static var AVPlayerItemNewErrorLogEntry: Foundation.NSNotification.Name {
    get {
        Self("AVPlayerItemNewErrorLogEntry")
    }
  }
  @available(macOS, introduced: 10.9, deprecated: 100000, message: "Use AVPlayerItem.newAccessLogEntryNotification instead.")
  @available(iOS, introduced: 6.0, deprecated: 100000, message: "Use AVPlayerItem.newAccessLogEntryNotification instead.")
  @available(tvOS, introduced: 9.0, deprecated: 100000, message: "Use AVPlayerItem.newAccessLogEntryNotification instead.")
  @available(watchOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.newAccessLogEntryNotification instead.")
  @available(visionOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.newAccessLogEntryNotification instead.")
  @_alwaysEmitIntoClient public static var AVPlayerItemNewAccessLogEntry: Foundation.NSNotification.Name {
    get {
        Self("AVPlayerItemNewAccessLogEntry")
    }
  }
  @available(macOS, introduced: 10.7, deprecated: 100000, message: "Use AVPlayerItem.didPlayToEndTimeNotification instead.")
  @available(iOS, introduced: 4.0, deprecated: 100000, message: "Use AVPlayerItem.didPlayToEndTimeNotification instead.")
  @available(tvOS, introduced: 9.0, deprecated: 100000, message: "Use AVPlayerItem.didPlayToEndTimeNotification instead.")
  @available(watchOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.didPlayToEndTimeNotification instead.")
  @available(visionOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.didPlayToEndTimeNotification instead.")
  @_alwaysEmitIntoClient public static var AVPlayerItemDidPlayToEndTime: Foundation.NSNotification.Name {
    get {
        Self("AVPlayerItemDidPlayToEndTimeNotification")
    }
  }
  @available(macOS, introduced: 10.7, deprecated: 100000, message: "Use AVPlayerItem.failedToPlayToEndTimeNotification instead.")
  @available(iOS, introduced: 4.3, deprecated: 100000, message: "Use AVPlayerItem.failedToPlayToEndTimeNotification instead.")
  @available(tvOS, introduced: 9.0, deprecated: 100000, message: "Use AVPlayerItem.failedToPlayToEndTimeNotification instead.")
  @available(watchOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.failedToPlayToEndTimeNotification instead.")
  @available(visionOS, introduced: 1.0, deprecated: 100000, message: "Use AVPlayerItem.failedToPlayToEndTimeNotification instead.")
  @_alwaysEmitIntoClient public static var AVPlayerItemFailedToPlayToEndTime: Foundation.NSNotification.Name {
    get {
        Self("AVPlayerItemFailedToPlayToEndTimeNotification")
    }
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
extension AVFoundation.AVPlayerItem : Observation.Observable {
}
@available(watchOS, unavailable)
extension AVFoundation.AVAssetImageGenerator {
  @available(macOS 13, iOS 16, tvOS 16, visionOS 1, *)
  @available(watchOS, unavailable)
  public func image(at time: CoreMedia.CMTime) async throws -> (image: CoreGraphics.CGImage, actualTime: CoreMedia.CMTime)
  #if compiler(>=5.3) && $SendingArgsAndResults
  @available(macOS 13, iOS 16, tvOS 16, visionOS 1, *)
  @available(watchOS, unavailable)
  public func images(for times: [CoreMedia.CMTime]) -> sending AVFoundation.AVAssetImageGenerator.Images
  #else
  @available(macOS 13, iOS 16, tvOS 16, visionOS 1, *)
  @available(watchOS, unavailable)
  public func images(for times: [CoreMedia.CMTime]) -> AVFoundation.AVAssetImageGenerator.Images
  #endif
  @available(macOS 13, iOS 16, tvOS 16, visionOS 1, *)
  @available(watchOS, unavailable)
  public struct Images : _Concurrency.AsyncSequence, _Concurrency.AsyncIteratorProtocol {
    @frozen public enum Element : Swift.Sendable {
      case success(requestedTime: CoreMedia.CMTime, image: CoreGraphics.CGImage, actualTime: CoreMedia.CMTime)
      case failure(requestedTime: CoreMedia.CMTime, error: any Swift.Error)
    }
    public func makeAsyncIterator() -> AVFoundation.AVAssetImageGenerator.Images
    #if compiler(>=5.3) && $NonescapableTypes
    public mutating func next() async -> AVFoundation.AVAssetImageGenerator.Images.Element?
    #endif
    @available(iOS 16, tvOS 16, visionOS 1, macOS 13, *)
    @available(watchOS, unavailable)
    public typealias AsyncIterator = AVFoundation.AVAssetImageGenerator.Images
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    @available(watchOS, unavailable, introduced: 11.0)
    @_implements(_Concurrency.AsyncIteratorProtocol, Failure) public typealias __AsyncIteratorProtocol_Failure = Swift.Never
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    @available(watchOS, unavailable, introduced: 11.0)
    @_implements(_Concurrency.AsyncSequence, Failure) public typealias __AsyncSequence_Failure = Swift.Never
  }
}
@available(macOS 13, iOS 16, tvOS 16, visionOS 1, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetImageGenerator.Images.Element {
  public var requestedTime: CoreMedia.CMTime {
    get
  }
  public var image: CoreGraphics.CGImage {
    get throws
  }
  public var actualTime: CoreMedia.CMTime {
    get throws
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriter {
  public func start() throws
}
@available(macOS 26.0, iOS 26.0, visionOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriterInput {
  @_hasMissingDesignatedInitializers public class TaggedPixelBufferGroupReceiver {
    #if compiler(>=5.3) && $NonescapableTypes
    public var sourcePixelBufferAttributes: CoreVideo.CVPixelBufferCreationAttributes? {
      get
    }
    #endif
    #if compiler(>=5.3) && $NonescapableTypes
    public var pixelBufferPool: CoreVideo.CVMutablePixelBuffer.Pool? {
      get
    }
    #endif
    #if compiler(>=5.3) && $AsyncExecutionBehaviorAttributes
    nonisolated(nonsending) public func append(_ taggedPixelBufferGroup: [CoreMedia.CMTaggedDynamicBuffer], with presentationTime: CoreMedia.CMTime) async throws
    #endif
    public func appendImmediately(_ taggedPixelBufferGroup: [CoreMedia.CMTaggedDynamicBuffer], with presentationTime: CoreMedia.CMTime) throws -> Swift.Bool
    public func finish()
    @objc deinit
  }
}
@available(macOS 26.0, iOS 26.0, visionOS 26.0, *)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetWriter {
  #if compiler(>=5.3) && $NonescapableTypes
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputTaggedPixelBufferGroupReceiver(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> sending AVFoundation.AVAssetWriterInput.TaggedPixelBufferGroupReceiver
  #else
  public func inputTaggedPixelBufferGroupReceiver(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> AVFoundation.AVAssetWriterInput.TaggedPixelBufferGroupReceiver
  #endif
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  #if compiler(>=5.3) && $SendingArgsAndResults
  public func inputTaggedPixelBufferGroupReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> sending (AVFoundation.AVAssetWriterInput.TaggedPixelBufferGroupReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #else
  public func inputTaggedPixelBufferGroupReceiverRequestingMultiPass(for input: AVFoundation.AVAssetWriterInput, pixelBufferAttributes attributes: CoreVideo.CVPixelBufferCreationAttributes?) -> (AVFoundation.AVAssetWriterInput.TaggedPixelBufferGroupReceiver, AVFoundation.AVAssetWriterInput.MultiPassController)
  #endif
  #endif
}
@available(macOS 10.15, iOS 13.0, tvOS 13.0, visionOS 1.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetExportSession {
  #if compiler(>=5.3) && $NonescapableTypes
  @backDeployed(before: macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0)
  final public func export(to url: Foundation.URL, as fileType: AVFoundation.AVFileType, isolation: isolated (any _Concurrency.Actor)? = #isolation) async throws {
		nonisolated(unsafe) let exportSessionForCancellingOnly = self
		outputURL = url
		outputFileType = fileType
		try await withTaskCancellationHandler {
			
			 
			
			guard status != .cancelled else {
				 
				 
				 
				throw CancellationError()
			}
			await export()
			
			 

			switch status {
			case .completed:
				 
				break
			case .failed:
				throw self.error!
			case .cancelled:
				throw CancellationError()
			case .unknown:
				fallthrough
			case .waiting:
				fallthrough
			default:
				fatalError("Unexpected terminal status \(status)")
			}
		} onCancel: {
			
			 

			exportSessionForCancellingOnly.cancelExport()
		}
	}
  #endif
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetExportSession {
  public enum State : Swift.Sendable {
    case pending
    case waiting
    case exporting(progress: Foundation.Progress)
  }
  public func states(updateInterval: Foundation.TimeInterval = .infinity) -> some Swift.Sendable & _Concurrency.AsyncSequence<AVFoundation.AVAssetExportSession.State, Swift.Never>
  
}
@available(macOS 13.0, iOS 16.0, tvOS 16.0, visionOS 1.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVRouteDetector : @unchecked Swift.Sendable {
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVMutableComposition {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMutableCompositionTrack]> {
    get
  }
}
@available(macOS 13, iOS 16, tvOS 16, watchOS 9, visionOS 1, *)
extension AVFoundation.AVMutableComposition {
  #if compiler(>=5.3) && $NonescapableTypes
  @backDeployed(before: macOS 15, iOS 18, tvOS 18, watchOS 11, visionOS 2)
  final public func insertTimeRange(_ timeRange: CoreMedia.CMTimeRange, of asset: AVFoundation.AVAsset, at time: CoreMedia.CMTime, isolation: isolated (any _Concurrency.Actor)? = #isolation) async throws {
		 
		let tracks = try await asset.load(.tracks)
		for track in tracks {
			let _ = try await track.load(.formatDescriptions)
		}

		 
		 
		 
		try {
			 
			try insertTimeRange(timeRange, of: asset, at: time)
		}()
	}
  #endif
}
@available(macOS 11.0, iOS 10.0, macCatalyst 14.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCapturePhotoOutput {
  @nonobjc public var supportedFlashModes: [AVFoundation.AVCaptureDevice.FlashMode] {
    get
  }
  @nonobjc public var availablePhotoPixelFormatTypes: [Darwin.OSType] {
    get
  }
  @nonobjc public var availableRawPhotoPixelFormatTypes: [Darwin.OSType] {
    get
  }
}
@available(macOS 10.15, iOS 11.0, macCatalyst 14.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCapturePhotoOutput {
  @available(macOS 10.15, iOS 11.0, macCatalyst 14.0, tvOS 17.0, *)
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @nonobjc @_alwaysEmitIntoClient public func supportedPhotoPixelFormatTypes(for fileType: AVFoundation.AVFileType) -> [Darwin.OSType] {
		return __supportedPhotoPixelFormatTypes(forFileType: fileType).map { $0.uint32Value } as [OSType]
	}
  @available(*, unavailable, message: "Use 'supportedPhotoPixelFormatTypes(for:) -> [OSType]' instead")
  @nonobjc public func supportedPhotoPixelFormatTypes(for fileType: AVFoundation.AVFileType) -> [Foundation.NSNumber]
  @available(iOS 11.0, macCatalyst 14.0, tvOS 17.0, *)
  @available(macOS, unavailable)
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @nonobjc @_alwaysEmitIntoClient public func supportedRawPhotoPixelFormatTypes(for fileType: AVFoundation.AVFileType) -> [Darwin.OSType] {
		return __supportedRawPhotoPixelFormatTypes(forFileType: fileType).map { $0.uint32Value } as [OSType]
	}
  @available(*, unavailable, message: "Use 'supportedRawPhotoPixelFormatTypes(for:) -> [OSType]' instead")
  @nonobjc public func supportedRawPhotoPixelFormatTypes(for fileType: AVFoundation.AVFileType) -> [Foundation.NSNumber]
}
@available(macOS 11.0, iOS 10.0, macCatalyst 14.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCapturePhotoSettings {
  @nonobjc public var availablePreviewPhotoPixelFormatTypes: [Darwin.OSType] {
    get
  }
}
@available(macOS 10.15, iOS 11.0, macCatalyst 14.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCapturePhoto {
  #if compiler(>=5.3) && $NonescapableTypes
  @available(*, unavailable, message: "Use 'cgImageRepresentation() -> CGImage?' instead")
  @nonobjc public func cgImageRepresentation() -> Swift.Unmanaged<CoreGraphics.CGImage>?
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(*, unavailable, message: "Use 'previewCGImageRepresentation() -> CGImage?' instead")
  @nonobjc public func previewCGImageRepresentation() -> Swift.Unmanaged<CoreGraphics.CGImage>?
  #endif
}
@available(macOS 14.4, iOS 17.4, tvOS 17.4, macCatalyst 17.4, visionOS 1.1, *)
@available(watchOS, unavailable)
extension AVFoundation.AVSampleBufferVideoRenderer {
  public enum PresentationTimeExpectation : Swift.Sendable {
    case none
    case monotonicallyIncreasing
    case minimumUpcoming(CoreMedia.CMTime)
  }
  public var presentationTimeExpectation: AVFoundation.AVSampleBufferVideoRenderer.PresentationTimeExpectation {
    @available(*, unavailable)
    get
    set
  }
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
  @available(watchOS, unavailable)
  public var recommendedPixelBufferAttributes: CoreVideo.CVPixelBufferAttributes {
    get
  }
}
@available(macOS 14.2, iOS 17.2, tvOS 17.2, watchOS 10.2, visionOS 1.1, *)
extension AVFoundation.AVPlayerVideoOutput {
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS, introduced: 14.2, deprecated: 100000, message: "Use AVPlayerVideoOutput.sample instead")
  @available(iOS, introduced: 17.2, deprecated: 100000, message: "Use AVPlayerVideoOutput.sample instead")
  @available(tvOS, introduced: 17.2, deprecated: 100000, message: "Use AVPlayerVideoOutput.sample instead")
  @available(watchOS, introduced: 10.2, deprecated: 100000, message: "Use AVPlayerVideoOutput.sample instead")
  @available(visionOS, introduced: 1.1, deprecated: 100000, message: "Use AVPlayerVideoOutput.sample instead")
  public func taggedBuffers(forHostTime hostTime: CoreMedia.CMTime) -> (taggedBufferGroup: [CoreMedia.CMTaggedBuffer], presentationTime: CoreMedia.CMTime, activeConfiguration: AVFoundation.AVPlayerVideoOutput.Configuration)?
  #endif
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
  public struct Sample : Swift.Sendable {
    public let taggedBuffers: [CoreMedia.CMTaggedDynamicBuffer]
    public let presentationTime: CoreMedia.CMTime
    public let activeConfiguration: AVFoundation.AVPlayerVideoOutput.Configuration
  }
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 26.0, iOS 26.0, tvOS 26.0, watchOS 26.0, visionOS 26.0, *)
  public func sample(forHostTime hostTime: CoreMedia.CMTime) -> AVFoundation.AVPlayerVideoOutput.Sample?
  #endif
}
@available(macOS 14.2, iOS 17.2, tvOS 17.2, watchOS 10.2, visionOS 1.1, *)
extension AVFoundation.AVVideoOutputSpecification {
  @available(macOS 14.2, iOS 17.2, tvOS 17.2, watchOS 10.2, visionOS 1.1, *)
  convenience public init(tagCollections: [[CoreMedia.CMTag]])
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS, introduced: 14.2, deprecated: 100000, message: "Use setOutputSettings instead")
  @available(iOS, introduced: 17.2, deprecated: 100000, message: "Use setOutputSettings instead")
  @available(tvOS, introduced: 17.2, deprecated: 100000, message: "Use setOutputSettings instead")
  @available(watchOS, introduced: 10.2, deprecated: 100000, message: "Use setOutputSettings instead")
  @available(visionOS, introduced: 1.1, deprecated: 100000, message: "Use setOutputSettings instead")
  public func setOutputPixelBufferAttributes(_ pixelBufferAttributes: [Swift.String : Any]?, for tagCollection: [CoreMedia.CMTag])
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, watchOS 11.0, visionOS 2.0, *)
  public func setOutputSettings(_ outputSettings: [Swift.String : any Swift.Sendable]?, for tagCollection: [CoreMedia.CMTag])
  #endif
  @available(macOS 14.2, iOS 17.2, tvOS 17.2, watchOS 10.2, visionOS 1.1, *)
  public var preferredTagCollections: [[CoreMedia.CMTag]] {
    get
  }
}
@available(macOS 14.2, iOS 17.2, tvOS 17.2, watchOS 10.2, visionOS 1.1, *)
extension AVFoundation.AVPlayerVideoOutput.Configuration {
  public var dataChannelDescription: [[CoreMedia.CMTag]] {
    get
  }
}
@available(macOS 14.2, iOS 17.2, tvOS 17.2, watchOS 10.2, visionOS 1.1, *)
extension Swift.Array where Element == CoreMedia.CMTag {
  public static func monoscopicForVideoOutput() -> [CoreMedia.CMTag]
  public static func stereoscopicForVideoOutput() -> [CoreMedia.CMTag]
}
extension Foundation.NSNotification.Name {
  @available(macOS, introduced: 10.7, deprecated: 15.0, renamed: "AVCaptureInput.Port.formatDescriptionDidChangeNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureInput.Port.formatDescriptionDidChangeNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureInput.Port.formatDescriptionDidChangeNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureInput.Port.formatDescriptionDidChangeNotification")
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureInputPortFormatDescriptionDidChange: Foundation.NSNotification.Name {
    get {
		AVCaptureInput.Port.formatDescriptionDidChangeNotification
	}
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var formatDescriptions: AVFoundation.AVAsyncProperty<Root, [CoreMedia.CMFormatDescription]> {
    get
  }
  public static var isPlayable: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  public static var isDecodable: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  public static var isEnabled: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  public static var isSelfContained: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
  public static var totalSampleDataLength: AVFoundation.AVAsyncProperty<Root, Swift.Int64> {
    get
  }
  public static var mediaCharacteristics: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMediaCharacteristic]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var timeRange: AVFoundation.AVAsyncProperty<Root, CoreMedia.CMTimeRange> {
    get
  }
  public static var naturalTimeScale: AVFoundation.AVAsyncProperty<Root, CoreMedia.CMTimeScale> {
    get
  }
  public static var estimatedDataRate: AVFoundation.AVAsyncProperty<Root, Swift.Float> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  #if compiler(>=5.3) && $NonescapableTypes
  public static var languageCode: AVFoundation.AVAsyncProperty<Root, Swift.String?> {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static var extendedLanguageTag: AVFoundation.AVAsyncProperty<Root, Swift.String?> {
    get
  }
  #endif
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var naturalSize: AVFoundation.AVAsyncProperty<Root, CoreFoundation.CGSize> {
    get
  }
  public static var preferredTransform: AVFoundation.AVAsyncProperty<Root, CoreFoundation.CGAffineTransform> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var preferredVolume: AVFoundation.AVAsyncProperty<Root, Swift.Float> {
    get
  }
  public static var hasAudioSampleDependencies: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var nominalFrameRate: AVFoundation.AVAsyncProperty<Root, Swift.Float> {
    get
  }
  public static var minFrameDuration: AVFoundation.AVAsyncProperty<Root, CoreMedia.CMTime> {
    get
  }
  public static var requiresFrameReordering: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var segments: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVAssetTrackSegment]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var commonMetadata: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMetadataItem]> {
    get
  }
  public static var metadata: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMetadataItem]> {
    get
  }
  public static var availableMetadataFormats: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMetadataFormat]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  public static var availableTrackAssociationTypes: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVAssetTrack.AssociationType]> {
    get
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVAssetTrack {
  @available(macOS 12, iOS 16, tvOS 16, watchOS 9, visionOS 1, *)
  public static var canProvideSampleCursors: AVFoundation.AVAsyncProperty<Root, Swift.Bool> {
    get
  }
}
@available(macOS 15, iOS 18, visionOS 2, *)
@available(watchOS, unavailable)
@available(tvOS, unavailable)
extension AVFoundation.AVAssetDownloadStorageManager : @unchecked Swift.Sendable {
}
@available(watchOS 6.0, *)
extension CoreMedia.CMTime : Swift._ObjectiveCBridgeable {
  public func _bridgeToObjectiveC() -> Foundation.NSValue
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _forceBridgeFromObjectiveC(_ source: Foundation.NSValue, result: inout CoreMedia.CMTime?)
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _conditionallyBridgeFromObjectiveC(_ source: Foundation.NSValue, result: inout CoreMedia.CMTime?) -> Swift.Bool
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _unconditionallyBridgeFromObjectiveC(_ source: Foundation.NSValue?) -> CoreMedia.CMTime
  #endif
  @available(watchOS 6.0, macOS 10.7, *)
  public typealias _ObjectiveCType = Foundation.NSValue
}
@available(watchOS 6.0, *)
extension CoreMedia.CMTimeRange : Swift._ObjectiveCBridgeable {
  public func _bridgeToObjectiveC() -> Foundation.NSValue
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _forceBridgeFromObjectiveC(_ source: Foundation.NSValue, result: inout CoreMedia.CMTimeRange?)
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _conditionallyBridgeFromObjectiveC(_ source: Foundation.NSValue, result: inout CoreMedia.CMTimeRange?) -> Swift.Bool
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _unconditionallyBridgeFromObjectiveC(_ source: Foundation.NSValue?) -> CoreMedia.CMTimeRange
  #endif
  @available(watchOS 6.0, macOS 10.7, *)
  public typealias _ObjectiveCType = Foundation.NSValue
}
@available(watchOS 6.0, *)
extension CoreMedia.CMTimeMapping : Swift._ObjectiveCBridgeable {
  public func _bridgeToObjectiveC() -> Foundation.NSValue
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _forceBridgeFromObjectiveC(_ source: Foundation.NSValue, result: inout CoreMedia.CMTimeMapping?)
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _conditionallyBridgeFromObjectiveC(_ source: Foundation.NSValue, result: inout CoreMedia.CMTimeMapping?) -> Swift.Bool
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  public static func _unconditionallyBridgeFromObjectiveC(_ source: Foundation.NSValue?) -> CoreMedia.CMTimeMapping
  #endif
  @available(watchOS 6.0, macOS 10.7, *)
  public typealias _ObjectiveCType = Foundation.NSValue
}
@available(macOS 12.3, iOS 15.4, tvOS 15.4, visionOS 1, *)
@available(watchOS, unavailable)
extension AVFoundation.AVCoordinatedPlaybackSuspension : @unchecked Swift.Sendable {
}
@available(macOS 15, iOS 18, tvOS 18, visionOS 2, *)
@available(watchOS, unavailable)
extension AVFoundation.AVPlaybackCoordinator : @unchecked Swift.Sendable {
}
@available(macOS 10.7, iOS 5.0, macCatalyst 14.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureVideoDataOutput {
  @nonobjc public var availableVideoPixelFormatTypes: [Darwin.OSType] {
    get
  }
}
@available(macOS 11.0, iOS 10.0, macCatalyst 14.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureDevice.Format {
  @nonobjc public var supportedColorSpaces: [AVFoundation.AVCaptureColorSpace] {
    get
  }
}
@available(macOS 13.0, iOS 16.0, macCatalyst 16.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureDevice.Format {
  @nonobjc public var supportedMaxPhotoDimensions: [CoreMedia.CMVideoDimensions] {
    get
  }
}
@available(macOS 13.0, iOS 16.0, macCatalyst 16.0, tvOS 17.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureDevice.Format {
  @nonobjc public var secondaryNativeResolutionZoomFactors: [CoreFoundation.CGFloat] {
    get
  }
}
@available(iOS 16.0, macCatalyst 16.0, tvOS 17.0, *)
@available(macOS, unavailable)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureDevice.Format {
  @available(iOS, introduced: 16.0, deprecated: 17.2, message: "Use AVCaptureDevice.Format.supportedVideoZoomRangesForDepthDataDelivery instead")
  @available(macCatalyst, introduced: 16.0, deprecated: 17.2, message: "Use AVCaptureDevice.Format.supportedVideoZoomRangesForDepthDataDelivery instead")
  @available(tvOS, introduced: 17.0, deprecated: 17.2, message: "Use AVCaptureDevice.Format.supportedVideoZoomRangesForDepthDataDelivery instead")
  @available(macOS, unavailable)
  @available(visionOS, unavailable)
  @nonobjc public var supportedVideoZoomFactorsForDepthDataDelivery: [CoreFoundation.CGFloat] {
    get
  }
}
@available(macOS 14.2, iOS 17.2, macCatalyst 17.2, tvOS 17.2, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureDevice.Format {
  @nonobjc public var supportedVideoZoomRangesForDepthDataDelivery: [Swift.ClosedRange<CoreFoundation.CGFloat>] {
    get
  }
}
@available(macOS 15.0, iOS 18.0, macCatalyst 18.0, tvOS 18.0, *)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureDevice.Format {
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 15.0, iOS 18.0, macCatalyst 18.0, tvOS 18.0, *)
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @nonobjc public var systemRecommendedVideoZoomRange: Swift.ClosedRange<CoreFoundation.CGFloat>? {
    get
  }
  #endif
  #if compiler(>=5.3) && $NonescapableTypes
  @available(macOS 15.0, iOS 18.0, macCatalyst 18.0, tvOS 18.0, *)
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @nonobjc public var systemRecommendedExposureBiasRange: Swift.ClosedRange<Swift.Float>? {
    get
  }
  #endif
}
extension Foundation.NSNotification.Name {
  @available(macOS, introduced: 10.7, deprecated: 15.0, renamed: "AVCaptureDevice.wasConnectedNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureDevice.wasConnectedNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureDevice.wasConnectedNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureDevice.wasConnectedNotification")
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureDeviceWasConnected: Foundation.NSNotification.Name {
    get {
		AVCaptureDevice.wasConnectedNotification
	}
  }
  @available(macOS, introduced: 10.7, deprecated: 15.0, renamed: "AVCaptureDevice.wasDisconnectedNotification")
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureDevice.wasDisconnectedNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureDevice.wasDisconnectedNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureDevice.wasDisconnectedNotification")
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureDeviceWasDisconnected: Foundation.NSNotification.Name {
    get {
		AVCaptureDevice.wasDisconnectedNotification
	}
  }
  @available(iOS, introduced: 4.0, deprecated: 18.0, renamed: "AVCaptureDevice.subjectAreaDidChangeNotification")
  @available(macCatalyst, introduced: 14.0, deprecated: 18.0, renamed: "AVCaptureDevice.subjectAreaDidChangeNotification")
  @available(tvOS, introduced: 17.0, deprecated: 18.0, renamed: "AVCaptureDevice.subjectAreaDidChangeNotification")
  @available(macOS, unavailable)
  @available(visionOS, unavailable)
  @available(watchOS, unavailable)
  @_alwaysEmitIntoClient public static var AVCaptureDeviceSubjectAreaDidChange: Foundation.NSNotification.Name {
    get {
		AVCaptureDevice.subjectAreaDidChangeNotification
	}
  }
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVFragmentedAsset {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVFragmentedAssetTrack]> {
    get
  }
}
@available(macOS 26.0, iOS 26.0, tvOS 26.0, visionOS 26.0, *)
@available(watchOS, unavailable)
extension AVFoundation.AVAssetReader {
  public func start() throws
}
@available(macOS 15.0, iOS 18.0, macCatalyst 15.0, *)
@available(watchOS, unavailable)
@available(tvOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVCaptionGroup : @unchecked Swift.Sendable {
}
extension AVFoundation.AVMovie {
  @available(macOS 10.10, iOS 13.0, watchOS 6.0, visionOS 1.0, *)
  @available(tvOS, unavailable)
  @_alwaysEmitIntoClient convenience public init(url: Foundation.URL) {
		self.init(url: url, options: nil)
	}
}
@available(macOS 12, iOS 15, watchOS 8, visionOS 1, *)
@available(tvOS, unavailable)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVMovie {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVMovieTrack]> {
    get
  }
}
@available(iOS 26.1, *)
@available(macOS, unavailable)
@available(macCatalyst, unavailable)
@available(tvOS, unavailable)
@available(visionOS, unavailable)
@available(watchOS, unavailable)
extension AVFoundation.AVCaptureSmartFramingMonitor : Observation.Observable {
}
extension AVFoundation.AVURLAsset {
  @available(macOS 10.7, iOS 4.0, tvOS 9.0, watchOS 1.0, visionOS 1.0, *)
  @_alwaysEmitIntoClient convenience public init(url: Foundation.URL) {
		self.init(url: url, options: nil)
	}
}
@available(macOS 12, iOS 15, tvOS 15, watchOS 8, visionOS 1, *)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVURLAsset {
  public static var tracks: AVFoundation.AVAsyncProperty<Root, [AVFoundation.AVAssetTrack]> {
    get
  }
}
@available(macOS 26.0, *)
@available(iOS, unavailable)
@available(tvOS, unavailable)
@available(watchOS, unavailable)
@available(visionOS, unavailable)
extension AVFoundation.AVPartialAsyncProperty where Root : AVFoundation.AVURLAsset {
  #if compiler(>=5.3) && $NonescapableTypes
  public static var sidecarURL: AVFoundation.AVAsyncProperty<Root, Foundation.URL?> {
    get
  }
  #endif
}

// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 6.1.2 effective-5.10 (swiftlang-6.1.2.1.2 clang-1700.0.13.5)
// swift-module-flags: -target arm64e-apple-macos15.5 -target-variant arm64e-apple-ios18.0-macabi -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -library-level api -enable-experimental-feature DebugDescriptionMacro -enable-bare-slash-regex -user-module-version 8.0.78 -module-name Vision
// swift-module-flags-ignorable:  -interface-compiler-version 6.1.2
import AVFoundation
import Accelerate
import CoreFoundation
import CoreGraphics
import CoreImage
import CoreML
import CoreMedia
import CoreVideo
import Darwin
import Foundation
import ImageIO
import MachO
import Swift
@_exported import Vision
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
import simd
import simd.types
import Accelerate.vecLib.vDSP
import Accelerate.vecLib
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum RequestDescriptor : Swift.CustomStringConvertible, Swift.Equatable, Swift.Sendable, Swift.Codable, Swift.Hashable {
  case detectFaceRectanglesRequest(Vision.DetectFaceRectanglesRequest.Revision)
  case detectHumanRectanglesRequest(Vision.DetectHumanRectanglesRequest.Revision)
  case classifyImageRequest(Vision.ClassifyImageRequest.Revision)
  case calculateImageAestheticsScoresRequest(Vision.CalculateImageAestheticsScoresRequest.Revision)
  case coreMLRequest(Vision.CoreMLRequest.Revision)
  case detectAnimalBodyPoseRequest(Vision.DetectAnimalBodyPoseRequest.Revision)
  case detectBarcodesRequest(Vision.DetectBarcodesRequest.Revision)
  case detectContoursRequest(Vision.DetectContoursRequest.Revision)
  case detectDocumentSegmentationRequest(Vision.DetectDocumentSegmentationRequest.Revision)
  case detectFaceCaptureQualityRequest(Vision.DetectFaceCaptureQualityRequest.Revision)
  case detectFaceLandmarksRequest(Vision.DetectFaceLandmarksRequest.Revision)
  case detectHorizonRequest(Vision.DetectHorizonRequest.Revision)
  case detectHumanBodyPoseRequest(Vision.DetectHumanBodyPoseRequest.Revision)
  case detectHumanBodyPose3DRequest(Vision.DetectHumanBodyPose3DRequest.Revision)
  case detectHumanHandPoseRequest(Vision.DetectHumanHandPoseRequest.Revision)
  case detectRectanglesRequest(Vision.DetectRectanglesRequest.Revision)
  case detectTextRectanglesRequest(Vision.DetectTextRectanglesRequest.Revision)
  case detectTrajectoriesRequest(Vision.DetectTrajectoriesRequest.Revision)
  case generateAttentionBasedSaliencyImageRequest(Vision.GenerateAttentionBasedSaliencyImageRequest.Revision)
  case generateImageFeaturePrintRequest(Vision.GenerateImageFeaturePrintRequest.Revision)
  case generateForegroundInstanceMaskRequest(Vision.GenerateForegroundInstanceMaskRequest.Revision)
  case generateObjectnessBasedSaliencyImageRequest(Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision)
  case generatePersonSegmentationRequest(Vision.GeneratePersonSegmentationRequest.Revision)
  case generatePersonInstanceMaskRequest(Vision.GeneratePersonInstanceMaskRequest.Revision)
  case recognizeAnimalsRequest(Vision.RecognizeAnimalsRequest.Revision)
  case recognizeTextRequest(Vision.RecognizeTextRequest.Revision)
  case trackHomographicImageRegistrationRequest(Vision.TrackHomographicImageRegistrationRequest.Revision)
  case trackObjectRequest(Vision.TrackObjectRequest.Revision)
  case trackOpticalFlowRequest(Vision.TrackOpticalFlowRequest.Revision)
  case trackRectangleRequest(Vision.TrackRectangleRequest.Revision)
  case trackTranslationalImageRegistrationRequest(Vision.TrackTranslationalImageRegistrationRequest.Revision)
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.RequestDescriptor, b: Vision.RequestDescriptor) -> Swift.Bool
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct GenerateObjectnessBasedSaliencyImageRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.SaliencyImageObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision, b: Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision, b: Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision? = nil)
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision
  public static let supportedRevisions: [Vision.GenerateObjectnessBasedSaliencyImageRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.GenerateObjectnessBasedSaliencyImageRequest, b: Vision.GenerateObjectnessBasedSaliencyImageRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct HumanBodyPose3DObservation : Vision.VisionObservation {
  public enum EstimationTechnique : Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case reference
    case measured
    public static func == (a: Vision.HumanBodyPose3DObservation.EstimationTechnique, b: Vision.HumanBodyPose3DObservation.EstimationTechnique) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public let heightEstimationTechnique: Vision.HumanBodyPose3DObservation.EstimationTechnique
  public let bodyHeight: Foundation.Measurement<Foundation.UnitLength>
  public let cameraOriginMatrix: simd.simd_float4x4
  public var availableJointNames: [Vision.HumanBodyPose3DObservation.JointName] {
    get
  }
  public var availableJointsGroupNames: [Vision.HumanBodyPose3DObservation.JointsGroupName] {
    get
  }
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func joint(for jointName: Vision.HumanBodyPose3DObservation.JointName) -> Vision.Joint3D?
  public func allJoints(in groupName: Vision.HumanBodyPose3DObservation.JointsGroupName? = nil) -> [Vision.HumanBodyPose3DObservation.JointName : Vision.Joint3D]
  public func pointInImage(for jointName: Vision.HumanBodyPose3DObservation.JointName) -> Vision.NormalizedPoint
  public func parentJointName(for jointName: Vision.HumanBodyPose3DObservation.JointName) -> Vision.HumanBodyPose3DObservation.JointName
  public func cameraRelativePosition(for jointName: Vision.HumanBodyPose3DObservation.JointName) -> simd.simd_float4x4
  public enum JointName : Swift.String, Swift.Hashable, Swift.Sendable, Swift.Codable {
    case topHead
    case centerHead
    case centerShoulder
    case leftShoulder
    case rightShoulder
    case leftElbow
    case rightElbow
    case leftWrist
    case rightWrist
    case leftHip
    case rightHip
    case leftKnee
    case rightKnee
    case leftAnkle
    case rightAnkle
    case root
    case spine
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public enum JointsGroupName : Swift.String, Swift.CaseIterable, Swift.Hashable, Swift.Sendable {
    case head
    case leftArm
    case leftLeg
    case rightArm
    case rightLeg
    case torso
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.HumanBodyPose3DObservation.JointsGroupName]
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    nonisolated public static var allCases: [Vision.HumanBodyPose3DObservation.JointsGroupName] {
      get
    }
    public var rawValue: Swift.String {
      get
    }
  }
  public static func == (a: Vision.HumanBodyPose3DObservation, b: Vision.HumanBodyPose3DObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
extension Vision.HumanBodyPose3DObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNHumanBodyPose3DObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanBodyPose3DObservation : Swift.Codable {
  public init(from decoder: any Swift.Decoder) throws
  public func encode(to encoder: any Swift.Encoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct RecognizedObjectObservation : Vision.VisionObservation, Vision.BoundingBoxProviding {
  public let labels: [Vision.ClassificationObservation]
  public let boundingBox: Vision.NormalizedRect
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.RecognizedObjectObservation, b: Vision.RecognizedObjectObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.RecognizedObjectObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.RecognizedObjectObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNRecognizedObjectObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol PoseProviding {
  associatedtype PoseJointName : Swift.Decodable, Swift.Encodable, Swift.Hashable, Swift.RawRepresentable where Self.PoseJointName.RawValue == Swift.String
  associatedtype PoseJointsGroupName : Swift.CaseIterable, Swift.RawRepresentable where Self.PoseJointsGroupName.RawValue == Swift.String
  var availableJointNames: [Self.PoseJointName] { get }
  var availableJointsGroupNames: [Self.PoseJointsGroupName] { get }
  func joint(for jointName: Self.PoseJointName) -> Vision.Joint?
  func allJoints(in groupName: Self.PoseJointsGroupName?) -> [Self.PoseJointName : Vision.Joint]
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum CoordinateOrigin {
  case upperLeft
  case lowerLeft
  public static func == (a: Vision.CoordinateOrigin, b: Vision.CoordinateOrigin) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct NormalizedPoint : Swift.Hashable, Swift.Equatable, Swift.Codable, Swift.Sendable, Swift.CustomStringConvertible {
  public init(x: CoreFoundation.CGFloat, y: CoreFoundation.CGFloat)
  public init(normalizedPoint: CoreFoundation.CGPoint)
  public init(imagePoint: CoreFoundation.CGPoint, in imageSize: CoreFoundation.CGSize)
  public init(imagePoint: CoreFoundation.CGPoint, in imageSize: CoreFoundation.CGSize, normalizedTo regionOfInterest: Vision.NormalizedRect)
  public static var zero: Vision.NormalizedPoint {
    get
  }
  public let cgPoint: CoreFoundation.CGPoint
  public var x: CoreFoundation.CGFloat {
    get
  }
  public var y: CoreFoundation.CGFloat {
    get
  }
  public func toImageCoordinates(from regionOfInterest: Vision.NormalizedRect, imageSize: CoreFoundation.CGSize, origin: Vision.CoordinateOrigin = .lowerLeft) -> CoreFoundation.CGPoint
  public func toImageCoordinates(_ imageSize: CoreFoundation.CGSize, origin: Vision.CoordinateOrigin = .lowerLeft) -> CoreFoundation.CGPoint
  public func verticallyFlipped() -> Vision.NormalizedPoint
  public func hash(into hasher: inout Swift.Hasher)
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.NormalizedPoint, b: Vision.NormalizedPoint) -> Swift.Bool
  public func encode(to encoder: any Swift.Encoder) throws
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectAnimalBodyPoseRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.AnimalBodyPoseObservation]
  public enum Revision : Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable, Swift.Comparable {
    case revision1
    public static func < (a: Vision.DetectAnimalBodyPoseRequest.Revision, b: Vision.DetectAnimalBodyPoseRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectAnimalBodyPoseRequest.Revision, b: Vision.DetectAnimalBodyPoseRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectAnimalBodyPoseRequest.Revision? = nil)
  public var supportedJointNames: [Vision.AnimalBodyPoseObservation.JointName] {
    get
  }
  public var supportedJointsGroupNames: [Vision.AnimalBodyPoseObservation.JointsGroupName] {
    get
  }
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectAnimalBodyPoseRequest.Revision
  public static let supportedRevisions: [Vision.DetectAnimalBodyPoseRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectAnimalBodyPoseRequest, b: Vision.DetectAnimalBodyPoseRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol TargetedRequest : Vision.VisionRequest {
}
@_hasMissingDesignatedInitializers @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class TargetedImageRequestHandler : Swift.Sendable {
  convenience public init(sourceURL: Foundation.URL, targetURL: Foundation.URL, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(source: CoreGraphics.CGImage, target: CoreGraphics.CGImage, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(source: CoreImage.CIImage, target: CoreImage.CIImage, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(source: CoreVideo.CVPixelBuffer, target: CoreVideo.CVPixelBuffer, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(source: CoreMedia.CMSampleBuffer, target: CoreMedia.CMSampleBuffer, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(source: Foundation.Data, target: Foundation.Data, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  final public func perform<T>(_ request: T) async throws -> T.Result where T : Vision.TargetedRequest
  final public func perform<each T>(_ request: repeat each T) async throws -> (repeat (each T).Result) where repeat each T : Vision.TargetedRequest
  final public func performAll(_ requests: some Collection<any TargetedRequest>) -> some _Concurrency.AsyncSequence<Vision.VisionResult, Swift.Never>
  
  @objc deinit
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct GenerateAttentionBasedSaliencyImageRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.SaliencyImageObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.GenerateAttentionBasedSaliencyImageRequest.Revision, b: Vision.GenerateAttentionBasedSaliencyImageRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.GenerateAttentionBasedSaliencyImageRequest.Revision, b: Vision.GenerateAttentionBasedSaliencyImageRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.GenerateAttentionBasedSaliencyImageRequest.Revision? = nil)
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.GenerateAttentionBasedSaliencyImageRequest.Revision
  public static let supportedRevisions: [Vision.GenerateAttentionBasedSaliencyImageRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.GenerateAttentionBasedSaliencyImageRequest, b: Vision.GenerateAttentionBasedSaliencyImageRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct RectangleObservation : Vision.VisionObservation, Vision.QuadrilateralProviding {
  public init(topLeft: Vision.NormalizedPoint, topRight: Vision.NormalizedPoint, bottomRight: Vision.NormalizedPoint, bottomLeft: Vision.NormalizedPoint)
  public let topLeft: Vision.NormalizedPoint
  public let topRight: Vision.NormalizedPoint
  public let bottomRight: Vision.NormalizedPoint
  public let bottomLeft: Vision.NormalizedPoint
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.RectangleObservation, b: Vision.RectangleObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.RectangleObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.RectangleObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNRectangleObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class TrackTranslationalImageRegistrationRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest, Vision.TargetedRequest {
  public typealias Result = Vision.ImageTranslationAlignmentObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.TrackTranslationalImageRegistrationRequest.Revision, b: Vision.TrackTranslationalImageRegistrationRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.TrackTranslationalImageRegistrationRequest.Revision, b: Vision.TrackTranslationalImageRegistrationRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.TrackTranslationalImageRegistrationRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  final public var supportedComputeStageDevices: [Vision.ComputeStage : [CoreML.MLComputeDevice]] {
    get
  }
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public var minimumLatencyFrameCount: Swift.Int {
    get
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public let revision: Vision.TrackTranslationalImageRegistrationRequest.Revision
  public static let supportedRevisions: [Vision.TrackTranslationalImageRegistrationRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct OpticalFlowObservation : Vision.VisionObservation, @unchecked Swift.Sendable {
  public var size: CoreFoundation.CGSize {
    get
  }
  public var pixelFormat: Darwin.OSType {
    get
  }
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func withUnsafePointer<R>(_ body: (Swift.UnsafeRawPointer) -> R) -> R
  public func flow(at point: Vision.NormalizedPoint) -> (Swift.Float, Swift.Float)
  public static func == (lhs: Vision.OpticalFlowObservation, rhs: Vision.OpticalFlowObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
extension Vision.OpticalFlowObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init?(_ observation: Vision.VNPixelBufferObservation)
}
public typealias NamedObjectsDictionary = [Swift.String : Any]
public typealias NamedObjectDataAccessBlock = (_ objectData: Foundation.Data) throws -> Swift.Void
public typealias NamedMultipleObjectDataAccessBlock = (_ namedObjectDataMap: [Swift.String : Foundation.Data]) throws -> Swift.Void
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ResourceVersion : Swift.Sendable, Swift.Codable, Swift.Hashable, Swift.Equatable, Swift.Comparable, Swift.CustomStringConvertible {
  public func hash(into hasher: inout Swift.Hasher)
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
  public var description: Swift.String {
    get
  }
  public static func == (lhs: Vision.ResourceVersion, rhs: Vision.ResourceVersion) -> Swift.Bool
  public static func < (lhs: Vision.ResourceVersion, rhs: Vision.ResourceVersion) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol QuadrilateralProviding : Vision.BoundingBoxProviding {
  var topLeft: Vision.NormalizedPoint { get }
  var topRight: Vision.NormalizedPoint { get }
  var bottomRight: Vision.NormalizedPoint { get }
  var bottomLeft: Vision.NormalizedPoint { get }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.QuadrilateralProviding {
  public var boundingBox: Vision.NormalizedRect {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectFaceCaptureQualityRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.FaceObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision3
    public static func < (a: Vision.DetectFaceCaptureQualityRequest.Revision, b: Vision.DetectFaceCaptureQualityRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectFaceCaptureQualityRequest.Revision, b: Vision.DetectFaceCaptureQualityRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectFaceCaptureQualityRequest.Revision? = nil)
  public var inputFaceObservations: [Vision.FaceObservation]?
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectFaceCaptureQualityRequest.Revision
  public static let supportedRevisions: [Vision.DetectFaceCaptureQualityRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectFaceCaptureQualityRequest, b: Vision.DetectFaceCaptureQualityRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class TrackObjectRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest {
  public typealias Result = Vision.DetectedObjectObservation?
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.TrackObjectRequest.Revision, b: Vision.TrackObjectRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.TrackObjectRequest.Revision, b: Vision.TrackObjectRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(detectedObject: any Vision.BoundingBoxProviding & Vision.VisionObservation, _ revision: Vision.TrackObjectRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  final public let inputObservation: any Vision.BoundingBoxProviding & Vision.VisionObservation
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public let revision: Vision.TrackObjectRequest.Revision
  public static let supportedRevisions: [Vision.TrackObjectRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol StatefulRequest : Vision.VisionRequest {
  var minimumLatencyFrameCount: Swift.Int { get }
  var frameAnalysisSpacing: CoreMedia.CMTime { get }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.StatefulRequest {
  public var minimumLatencyFrameCount: Swift.Int {
    get
  }
  public static func == (lhs: Self, rhs: Self) -> Swift.Bool
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.StatefulRequest {
  public func hash(into hasher: inout Swift.Hasher)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct GenerateImageFeaturePrintRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.FeaturePrintObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.GenerateImageFeaturePrintRequest.Revision, b: Vision.GenerateImageFeaturePrintRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.GenerateImageFeaturePrintRequest.Revision, b: Vision.GenerateImageFeaturePrintRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.GenerateImageFeaturePrintRequest.Revision? = nil)
  public var cropAndScaleAction: Vision.ImageCropAndScaleAction
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.GenerateImageFeaturePrintRequest.Revision
  public static let supportedRevisions: [Vision.GenerateImageFeaturePrintRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.GenerateImageFeaturePrintRequest, b: Vision.GenerateImageFeaturePrintRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol ImageProcessingRequest : Vision.VisionRequest {
  var regionOfInterest: Vision.NormalizedRect { get set }
  func perform(on pixelBuffer: CoreVideo.CVPixelBuffer, orientation: ImageIO.CGImagePropertyOrientation?) async throws -> Self.Result
  func perform(on url: Foundation.URL, orientation: ImageIO.CGImagePropertyOrientation?) async throws -> Self.Result
  func perform(on image: CoreGraphics.CGImage, orientation: ImageIO.CGImagePropertyOrientation?) async throws -> Self.Result
  func perform(on image: CoreImage.CIImage, orientation: ImageIO.CGImagePropertyOrientation?) async throws -> Self.Result
  func perform(on sampleBuffer: CoreMedia.CMSampleBuffer, orientation: ImageIO.CGImagePropertyOrientation?) async throws -> Self.Result
  func perform(on data: Foundation.Data, orientation: ImageIO.CGImagePropertyOrientation?) async throws -> Self.Result
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.ImageProcessingRequest {
  public func perform(on pixelBuffer: CoreVideo.CVPixelBuffer, orientation: ImageIO.CGImagePropertyOrientation? = nil) async throws -> Self.Result
  public func perform(on url: Foundation.URL, orientation: ImageIO.CGImagePropertyOrientation? = nil) async throws -> Self.Result
  public func perform(on image: CoreGraphics.CGImage, orientation: ImageIO.CGImagePropertyOrientation? = nil) async throws -> Self.Result
  public func perform(on image: CoreImage.CIImage, orientation: ImageIO.CGImagePropertyOrientation? = nil) async throws -> Self.Result
  public func perform(on sampleBuffer: CoreMedia.CMSampleBuffer, orientation: ImageIO.CGImagePropertyOrientation? = nil) async throws -> Self.Result
  public func perform(on data: Foundation.Data, orientation: ImageIO.CGImagePropertyOrientation? = nil) async throws -> Self.Result
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct TextObservation : Vision.VisionObservation, Vision.QuadrilateralProviding {
  public let characterBoxes: [Vision.RectangleObservation]?
  public let boundingBox: Vision.NormalizedRect
  public let topLeft: Vision.NormalizedPoint
  public let topRight: Vision.NormalizedPoint
  public let bottomRight: Vision.NormalizedPoint
  public let bottomLeft: Vision.NormalizedPoint
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.TextObservation, b: Vision.TextObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.TextObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.TextObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNTextObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct Joint : Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable, Swift.CustomStringConvertible {
  public let location: Vision.NormalizedPoint
  public let jointName: Swift.String
  public let confidence: Swift.Float
  public func distance(to joint: Vision.Joint) -> CoreFoundation.CGFloat
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.Joint, b: Vision.Joint) -> Swift.Bool
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct FeaturePrintObservation : Vision.VisionObservation {
  public let data: Foundation.Data
  public let elementCount: Swift.Int
  public let elementType: Vision.ElementType
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func distance(to featurePrint: Vision.FeaturePrintObservation) throws -> Swift.Double
  public static func == (a: Vision.FeaturePrintObservation, b: Vision.FeaturePrintObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.FeaturePrintObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.FeaturePrintObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNFeaturePrintObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class VideoProcessor : Swift.Sendable {
  public enum Cadence : Swift.Sendable, Swift.Equatable, Swift.Hashable {
    case timeInterval(_: CoreMedia.CMTime)
    case frameInterval(_: Swift.Int)
    public static func == (a: Vision.VideoProcessor.Cadence, b: Vision.VideoProcessor.Cadence) -> Swift.Bool
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
  }
  public init(_ videoURL: Foundation.URL)
  final public func addRequest<T>(_ request: T, cadence: Vision.VideoProcessor.Cadence? = nil) async throws -> some _Concurrency.AsyncSequence<T.Result, any Swift.Error> where T : Vision.VisionRequest
  
  final public func removeRequest(_ request: any Vision.VisionRequest) async -> Swift.Bool
  final public func cancel() async
  final public func startAnalysis(of timeRange: CoreMedia.CMTimeRange? = nil)
  @objc deinit
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum VisionError : Swift.Error {
  case dataUnavailable(Swift.String)
  case internalError(Swift.String)
  case invalidArgument(Swift.String)
  case invalidFormat(Swift.String)
  case invalidImage(Swift.String)
  case invalidModel(Swift.String)
  case invalidOperation(Swift.String)
  case ioError(Swift.String)
  case operationFailed(Swift.String)
  case outOfBoundsError(Swift.String)
  case outOfMemory(Swift.String)
  case pixelBufferCreationFailed(CoreVideo.CVReturn)
  case requestCancelled(Swift.String)
  case timeout(Swift.String)
  case timeStampNotFound(Swift.String)
  case unsupportedComputeDevice(Swift.String)
  case unsupportedComputeStage(Swift.String)
  case unsupportedRequest(Swift.String)
  case unsupportedRevision(Swift.String)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.VisionError : Foundation.LocalizedError {
  public var errorDescription: Swift.String? {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.VisionError {
  public var description: Swift.String {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct HumanHandPoseObservation : Vision.VisionObservation, Vision.PoseProviding {
  public enum Chirality : Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
    case left
    case right
    public static func == (a: Vision.HumanHandPoseObservation.Chirality, b: Vision.HumanHandPoseObservation.Chirality) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public let chirality: Vision.HumanHandPoseObservation.Chirality?
  public func allJoints(in groupName: Vision.HumanHandPoseObservation.PoseJointsGroupName? = nil) -> [Vision.HumanHandPoseObservation.PoseJointName : Vision.Joint]
  public var keypoints: CoreML.MLMultiArray {
    get throws
  }
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public typealias PoseJointName = Vision.HumanHandPoseObservation.JointName
  public typealias PoseJointsGroupName = Vision.HumanHandPoseObservation.JointsGroupName
  public enum JointName : Swift.String, Swift.Hashable, Swift.Sendable, Swift.Codable {
    case thumbTip
    case thumbIP
    case thumbMP
    case thumbCMC
    case indexTip
    case indexDIP
    case indexPIP
    case indexMCP
    case middleTip
    case middleDIP
    case middlePIP
    case middleMCP
    case ringTip
    case ringDIP
    case ringPIP
    case ringMCP
    case littleTip
    case littleDIP
    case littlePIP
    case littleMCP
    case wrist
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public enum JointsGroupName : Swift.String, Swift.CaseIterable, Swift.Hashable, Swift.Sendable {
    case thumb
    case indexFinger
    case littleFinger
    case middleFinger
    case ringFinger
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.HumanHandPoseObservation.JointsGroupName]
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    nonisolated public static var allCases: [Vision.HumanHandPoseObservation.JointsGroupName] {
      get
    }
    public var rawValue: Swift.String {
      get
    }
  }
  public static func == (a: Vision.HumanHandPoseObservation, b: Vision.HumanHandPoseObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanHandPoseObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.HumanHandPoseObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNHumanHandPoseObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectFaceLandmarksRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.FaceObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision3
    public static func < (a: Vision.DetectFaceLandmarksRequest.Revision, b: Vision.DetectFaceLandmarksRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectFaceLandmarksRequest.Revision, b: Vision.DetectFaceLandmarksRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectFaceLandmarksRequest.Revision? = nil)
  public var inputFaceObservations: [Vision.FaceObservation]?
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectFaceLandmarksRequest.Revision
  public static let supportedRevisions: [Vision.DetectFaceLandmarksRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectFaceLandmarksRequest, b: Vision.DetectFaceLandmarksRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct RecognizeAnimalsRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.RecognizedObjectObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.RecognizeAnimalsRequest.Revision, b: Vision.RecognizeAnimalsRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.RecognizeAnimalsRequest.Revision, b: Vision.RecognizeAnimalsRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.RecognizeAnimalsRequest.Revision? = nil)
  public enum Animal : Swift.String, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case dog
    case cat
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public var supportedAnimals: [Vision.RecognizeAnimalsRequest.Animal] {
    get
  }
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.RecognizeAnimalsRequest.Revision
  public static let supportedRevisions: [Vision.RecognizeAnimalsRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.RecognizeAnimalsRequest, b: Vision.RecognizeAnimalsRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectBarcodesRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.BarcodeObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision4
    public static func < (a: Vision.DetectBarcodesRequest.Revision, b: Vision.DetectBarcodesRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectBarcodesRequest.Revision, b: Vision.DetectBarcodesRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectBarcodesRequest.Revision? = nil)
  public var supportedSymbologies: [Vision.BarcodeSymbology] {
    get
  }
  public var symbologies: [Vision.BarcodeSymbology]
  public var coalescesCompositeSymbologies: Swift.Bool
  public static let supportedRevisions: [Vision.DetectBarcodesRequest.Revision]
  public let revision: Vision.DetectBarcodesRequest.Revision
  public var regionOfInterest: Vision.NormalizedRect
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectBarcodesRequest, b: Vision.DetectBarcodesRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 10.13, iOS 11.0, tvOS 11.0, *)
extension Vision.VNFaceLandmarkRegion2D {
  @nonobjc public var normalizedPoints: [CoreFoundation.CGPoint] {
    get
  }
  @nonobjc public func pointsInImage(imageSize: CoreFoundation.CGSize) -> [CoreFoundation.CGPoint]
  @available(macOS 10.15, iOS 13.0, tvOS 13.0, *)
  @nonobjc public var precisionEstimatesPerPoint: [Swift.Float]? {
    get
  }
}
@available(macOS 10.15, iOS 13.0, tvOS 13.0, *)
extension Vision.VNFaceObservation {
  @nonobjc public var faceCaptureQuality: Swift.Float? {
    get
  }
}
@available(macOS 10.15, iOS 13.0, tvOS 13.0, *)
extension Vision.VNRecognizedText {
  @nonobjc public func boundingBox(for range: Swift.Range<Swift.String.Index>) throws -> Vision.VNRectangleObservation?
}
@available(macOS 11.0, iOS 14.0, tvOS 14.0, *)
extension Vision.VNContour {
  @nonobjc public var normalizedPoints: [simd.simd_float2] {
    get
  }
}
@available(macOS 14.0, iOS 17.0, tvOS 17.0, *)
extension Vision.VNDetectHumanBodyPoseRequest {
  @nonobjc public var supportedJointNames: [Vision.VNHumanBodyPoseObservation.JointName] {
    get throws
  }
  @nonobjc public var supportedJointsGroupNames: [Vision.VNHumanBodyPoseObservation.JointsGroupName] {
    get throws
  }
}
@available(macOS 14.0, iOS 17.0, tvOS 17.0, *)
extension Vision.VNDetectHumanHandPoseRequest {
  @nonobjc public var supportedJointNames: [Vision.VNHumanHandPoseObservation.JointName] {
    get throws
  }
  @nonobjc public var supportedJointsGroupNames: [Vision.VNHumanHandPoseObservation.JointsGroupName] {
    get throws
  }
}
@available(macOS 14.0, iOS 17.0, tvOS 17.0, *)
extension Vision.VNDetectAnimalBodyPoseRequest {
  @nonobjc public var supportedJointNames: [Vision.VNAnimalBodyPoseObservation.JointName] {
    get throws
  }
  @nonobjc public var supportedJointsGroupNames: [Vision.VNAnimalBodyPoseObservation.JointsGroupName] {
    get throws
  }
}
@available(macOS 14.0, iOS 17.0, tvOS 17.0, *)
extension Vision.VNHumanBodyPose3DObservation {
  @nonobjc public func cameraRelativePosition(_ jointName: Vision.VNHumanBodyPose3DObservation.JointName) throws -> simd.simd_float4x4
}
@available(macOS 14.0, iOS 17.0, tvOS 17.0, *)
extension Vision.VNDetectHumanBodyPose3DRequest {
  @nonobjc public var supportedJointNames: [Vision.VNHumanBodyPose3DObservation.JointName] {
    get throws
  }
  @nonobjc public var supportedJointsGroupNames: [Vision.VNHumanBodyPose3DObservation.JointsGroupName] {
    get throws
  }
}
extension Vision.VNBarcodeSymbology {
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "aztec")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "aztec")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "aztec")
  @available(visionOS, deprecated: 1.0, renamed: "aztec")
  public static var Aztec: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "code39")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "code39")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "code39")
  @available(visionOS, deprecated: 1.0, renamed: "code39")
  public static var Code39: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "code39Checksum")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "code39Checksum")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "code39Checksum")
  @available(visionOS, deprecated: 1.0, renamed: "code39Checksum")
  public static var Code39Checksum: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "code39FullASCII")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "code39FullASCII")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "code39FullASCII")
  @available(visionOS, deprecated: 1.0, renamed: "code39FullASCII")
  public static var Code39FullASCII: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "code39FullASCIIChecksum")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "code39FullASCIIChecksum")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "code39FullASCIIChecksum")
  @available(visionOS, deprecated: 1.0, renamed: "code39FullASCIIChecksum")
  public static var Code39FullASCIIChecksum: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "code93")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "code93")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "code93")
  @available(visionOS, deprecated: 1.0, renamed: "code93")
  public static var Code93: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "code93i")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "code93i")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "code93i")
  @available(visionOS, deprecated: 1.0, renamed: "code93i")
  public static var Code93i: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "code128")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "code128")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "code128")
  @available(visionOS, deprecated: 1.0, renamed: "code128")
  public static var Code128: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "dataMatrix")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "dataMatrix")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "dataMatrix")
  @available(visionOS, deprecated: 1.0, renamed: "dataMatrix")
  public static var DataMatrix: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "ean8")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "ean8")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "ean8")
  @available(visionOS, deprecated: 1.0, renamed: "ean8")
  public static var EAN8: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "ean13")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "ean13")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "ean13")
  @available(visionOS, deprecated: 1.0, renamed: "ean13")
  public static var EAN13: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "i2of5")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "i2of5")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "i2of5")
  @available(visionOS, deprecated: 1.0, renamed: "i2of5")
  public static var I2of5: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "i2of5Checksum")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "i2of5Checksum")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "i2of5Checksum")
  @available(visionOS, deprecated: 1.0, renamed: "i2of5Checksum")
  public static var I2of5Checksum: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "itf14")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "itf14")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "itf14")
  @available(visionOS, deprecated: 1.0, renamed: "itf14")
  public static var ITF14: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "pdf417")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "pdf417")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "pdf417")
  @available(visionOS, deprecated: 1.0, renamed: "pdf417")
  public static var PDF417: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "qr")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "qr")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "qr")
  @available(visionOS, deprecated: 1.0, renamed: "qr")
  public static var QR: Vision.VNBarcodeSymbology {
    get
  }
  @available(macOS, introduced: 10.13, deprecated: 12.0, renamed: "upce")
  @available(iOS, introduced: 11.0, deprecated: 15.0, renamed: "upce")
  @available(tvOS, introduced: 11.0, deprecated: 15.0, renamed: "upce")
  @available(visionOS, deprecated: 1.0, renamed: "upce")
  public static var UPCE: Vision.VNBarcodeSymbology {
    get
  }
}
@available(macOS 14.0, iOS 17.0, tvOS 17.0, *)
extension Vision.VNRequest {
  @nonobjc public var supportedComputeStageDevices: [Vision.VNComputeStage : [CoreML.MLComputeDevice]] {
    get throws
  }
  @nonobjc public func computeDevice(for computeStage: Vision.VNComputeStage) -> CoreML.MLComputeDevice?
  @nonobjc public func setComputeDevice(_ computeDevice: CoreML.MLComputeDevice?, for computeStage: Vision.VNComputeStage)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct Joint3D : Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
  public let position: simd.simd_float4x4
  public let localPosition: simd.simd_float4x4
  public let identifier: Swift.String
  public let parentJoint: Swift.String
  public init(from decoder: any Swift.Decoder) throws
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public init(position: simd.simd_float4x4, localPosition: simd.simd_float4x4, identifer: Swift.String, parentJoint: Swift.String)
  public static func == (a: Vision.Joint3D, b: Vision.Joint3D) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectHumanBodyPoseRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.HumanBodyPoseObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.DetectHumanBodyPoseRequest.Revision, b: Vision.DetectHumanBodyPoseRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectHumanBodyPoseRequest.Revision, b: Vision.DetectHumanBodyPoseRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectHumanBodyPoseRequest.Revision? = nil)
  public var supportedJointNames: [Vision.HumanBodyPoseObservation.JointName] {
    get
  }
  public var supportedJointsGroupNames: [Vision.HumanBodyPoseObservation.JointsGroupName] {
    get
  }
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectHumanBodyPoseRequest.Revision
  public static let supportedRevisions: [Vision.DetectHumanBodyPoseRequest.Revision]
  public var detectsHands: Swift.Bool
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectHumanBodyPoseRequest, b: Vision.DetectHumanBodyPoseRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class DetectTrajectoriesRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest {
  public typealias Result = [Vision.TrajectoryObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectTrajectoriesRequest.Revision, b: Vision.DetectTrajectoriesRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectTrajectoriesRequest.Revision, b: Vision.DetectTrajectoriesRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(trajectoryLength: Swift.Int, _ revision: Vision.DetectTrajectoriesRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  final public var targetFrameTime: CoreMedia.CMTime {
    get
    set
  }
  final public var objectMinimumNormalizedRadius: Swift.Float {
    get
    set
  }
  final public var objectMaximumNormalizedRadius: Swift.Float {
    get
    set
  }
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public let trajectoryLength: Swift.Int
  final public var minimumLatencyFrameCount: Swift.Int {
    get
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public let revision: Vision.DetectTrajectoriesRequest.Revision
  public static let supportedRevisions: [Vision.DetectTrajectoriesRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct HorizonObservation : Vision.VisionObservation {
  public let transform: CoreFoundation.CGAffineTransform
  public let angle: Foundation.Measurement<Foundation.UnitAngle>
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func transform(for imageSize: CoreFoundation.CGSize) -> CoreFoundation.CGAffineTransform
  public static func == (a: Vision.HorizonObservation, b: Vision.HorizonObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HorizonObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.HorizonObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNHorizonObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectHumanHandPoseRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.HumanHandPoseObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectHumanHandPoseRequest.Revision, b: Vision.DetectHumanHandPoseRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectHumanHandPoseRequest.Revision, b: Vision.DetectHumanHandPoseRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectHumanHandPoseRequest.Revision? = nil)
  public var supportedJointNames: [Vision.HumanHandPoseObservation.JointName] {
    get
  }
  public var supportedJointsGroupNames: [Vision.HumanHandPoseObservation.JointsGroupName] {
    get throws
  }
  public var maximumHandCount: Swift.Int
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectHumanHandPoseRequest.Revision
  public static let supportedRevisions: [Vision.DetectHumanHandPoseRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectHumanHandPoseRequest, b: Vision.DetectHumanHandPoseRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct CalculateImageAestheticsScoresRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.ImageAestheticsScoresObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.CalculateImageAestheticsScoresRequest.Revision, b: Vision.CalculateImageAestheticsScoresRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.CalculateImageAestheticsScoresRequest.Revision, b: Vision.CalculateImageAestheticsScoresRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.CalculateImageAestheticsScoresRequest.Revision? = nil)
  public var cropAndScaleAction: Vision.ImageCropAndScaleAction
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.CalculateImageAestheticsScoresRequest.Revision
  public static let supportedRevisions: [Vision.CalculateImageAestheticsScoresRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.CalculateImageAestheticsScoresRequest, b: Vision.CalculateImageAestheticsScoresRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct NormalizedRect : Swift.Equatable, Swift.Hashable, Swift.Codable, Swift.Sendable, Swift.CustomStringConvertible {
  public init(x: CoreFoundation.CGFloat, y: CoreFoundation.CGFloat, width: CoreFoundation.CGFloat, height: CoreFoundation.CGFloat)
  public init(imageRect: CoreFoundation.CGRect, in imageSize: CoreFoundation.CGSize)
  public init(imageRect: CoreFoundation.CGRect, in imageSize: CoreFoundation.CGSize, normalizedTo regionOfInterest: Vision.NormalizedRect)
  public init(normalizedRect: CoreFoundation.CGRect)
  public static var fullImage: Vision.NormalizedRect {
    get
  }
  public let cgRect: CoreFoundation.CGRect
  public var origin: CoreFoundation.CGPoint {
    get
  }
  public var width: CoreFoundation.CGFloat {
    get
  }
  public var height: CoreFoundation.CGFloat {
    get
  }
  public func toImageCoordinates(_ imageSize: CoreFoundation.CGSize, origin: Vision.CoordinateOrigin = .lowerLeft) -> CoreFoundation.CGRect
  public func toImageCoordinates(from regionOfInterest: Vision.NormalizedRect, imageSize: CoreFoundation.CGSize, origin: Vision.CoordinateOrigin = .lowerLeft) -> CoreFoundation.CGRect
  public func verticallyFlipped() -> Vision.NormalizedRect
  public func hash(into hasher: inout Swift.Hasher)
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.NormalizedRect, b: Vision.NormalizedRect) -> Swift.Bool
  public func encode(to encoder: any Swift.Encoder) throws
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct RecognizedTextObservation : Vision.VisionObservation, Vision.QuadrilateralProviding {
  public var topLeft: Vision.NormalizedPoint
  public var topRight: Vision.NormalizedPoint
  public var bottomRight: Vision.NormalizedPoint
  public var bottomLeft: Vision.NormalizedPoint
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func topCandidates(_ maxCandidateCount: Swift.Int) -> [Vision.RecognizedText]
  public static func == (a: Vision.RecognizedTextObservation, b: Vision.RecognizedTextObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.RecognizedTextObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.RecognizedTextObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNRecognizedTextObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct CoreMLFeatureValueObservation : Vision.VisionObservation {
  public let featureName: Swift.String
  public let featureValue: CoreML.MLSendableFeatureValue
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.CoreMLFeatureValueObservation, b: Vision.CoreMLFeatureValueObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.CoreMLFeatureValueObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.CoreMLFeatureValueObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init?(_ observation: Vision.VNCoreMLFeatureValueObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol VisionObservation : Swift.CustomStringConvertible, Swift.Decodable, Swift.Encodable, Swift.Hashable, Swift.Sendable {
  var uuid: Foundation.UUID { get }
  var confidence: Swift.Float { get }
  var timeRange: CoreMedia.CMTimeRange? { get }
  var originatingRequestDescriptor: Vision.RequestDescriptor? { get }
  func hash(into hasher: inout Swift.Hasher)
  var description: Swift.String { get }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.VisionObservation {
  public func hash(into hasher: inout Swift.Hasher)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ClassificationObservation : Vision.VisionObservation, @unchecked Swift.Sendable {
  public let identifier: Swift.String
  public var hasPrecisionRecallCurve: Swift.Bool {
    get
  }
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public func hasMinimumRecall(_ minimumRecall: Swift.Float, forPrecision precision: Swift.Float) -> Swift.Bool
  public func hasMinimumPrecision(_ minimumPrecision: Swift.Float, forRecall recall: Swift.Float) -> Swift.Bool
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public static func == (a: Vision.ClassificationObservation, b: Vision.ClassificationObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.ClassificationObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.ClassificationObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNClassificationObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol VisionRequest : Swift.CustomStringConvertible, Swift.Hashable, Swift.Sendable {
  var supportedComputeStageDevices: [Vision.ComputeStage : [CoreML.MLComputeDevice]] { get }
  func computeDevice(for computeStage: Vision.ComputeStage) -> CoreML.MLComputeDevice?
  mutating func setComputeDevice(_ computeDevice: CoreML.MLComputeDevice?, for computeStage: Vision.ComputeStage)
  var descriptor: Vision.RequestDescriptor { get }
  associatedtype Result
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectDocumentSegmentationRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.DetectedDocumentObservation?
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectDocumentSegmentationRequest.Revision, b: Vision.DetectDocumentSegmentationRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectDocumentSegmentationRequest.Revision, b: Vision.DetectDocumentSegmentationRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectDocumentSegmentationRequest.Revision? = nil)
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectDocumentSegmentationRequest.Revision
  public static let supportedRevisions: [Vision.DetectDocumentSegmentationRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectDocumentSegmentationRequest, b: Vision.DetectDocumentSegmentationRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class TrackHomographicImageRegistrationRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest, Vision.TargetedRequest {
  public typealias Result = Vision.ImageHomographicAlignmentObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.TrackHomographicImageRegistrationRequest.Revision, b: Vision.TrackHomographicImageRegistrationRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.TrackHomographicImageRegistrationRequest.Revision, b: Vision.TrackHomographicImageRegistrationRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.TrackHomographicImageRegistrationRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public var minimumLatencyFrameCount: Swift.Int {
    get
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public let revision: Vision.TrackHomographicImageRegistrationRequest.Revision
  public static let supportedRevisions: [Vision.TrackHomographicImageRegistrationRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct CoreMLModelContainer : Swift.Equatable, @unchecked Swift.Sendable, Swift.Hashable {
  public init(model: CoreML.MLModel, featureProvider: (any CoreML.MLFeatureProvider)? = nil) throws
  public var inputImageFeatureName: Swift.String
  public func hash(into hasher: inout Swift.Hasher)
  public static func == (lhs: Vision.CoreMLModelContainer, rhs: Vision.CoreMLModelContainer) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct CoreMLRequest : Vision.ImageProcessingRequest {
  public typealias Result = [any Vision.VisionObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.CoreMLRequest.Revision, b: Vision.CoreMLRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.CoreMLRequest.Revision, b: Vision.CoreMLRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(model: Vision.CoreMLModelContainer, _ revision: Vision.CoreMLRequest.Revision? = nil)
  public let modelContainer: Vision.CoreMLModelContainer
  public var supportedIdentifiers: [Swift.String]? {
    get
  }
  public var cropAndScaleAction: Vision.ImageCropAndScaleAction
  public var regionOfInterest: Vision.NormalizedRect
  public var supportedComputeStageDevices: [Vision.ComputeStage : [CoreML.MLComputeDevice]] {
    get
  }
  public let revision: Vision.CoreMLRequest.Revision
  public static let supportedRevisions: [Vision.CoreMLRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.CoreMLRequest, b: Vision.CoreMLRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectHumanRectanglesRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.HumanObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.DetectHumanRectanglesRequest.Revision, b: Vision.DetectHumanRectanglesRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectHumanRectanglesRequest.Revision, b: Vision.DetectHumanRectanglesRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectHumanRectanglesRequest.Revision? = nil)
  public var upperBodyOnly: Swift.Bool
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectHumanRectanglesRequest.Revision
  public static let supportedRevisions: [Vision.DetectHumanRectanglesRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectHumanRectanglesRequest, b: Vision.DetectHumanRectanglesRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class GeneratePersonSegmentationRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest {
  public typealias Result = Vision.PixelBufferObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.GeneratePersonSegmentationRequest.Revision, b: Vision.GeneratePersonSegmentationRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.GeneratePersonSegmentationRequest.Revision, b: Vision.GeneratePersonSegmentationRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.GeneratePersonSegmentationRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  public enum QualityLevel : Swift.CaseIterable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case accurate
    case balanced
    case fast
    public static func == (a: Vision.GeneratePersonSegmentationRequest.QualityLevel, b: Vision.GeneratePersonSegmentationRequest.QualityLevel) -> Swift.Bool
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.GeneratePersonSegmentationRequest.QualityLevel]
    nonisolated public static var allCases: [Vision.GeneratePersonSegmentationRequest.QualityLevel] {
      get
    }
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  final public var qualityLevel: Vision.GeneratePersonSegmentationRequest.QualityLevel {
    get
    set
  }
  final public var outputPixelFormatType: Darwin.OSType {
    get
    set
  }
  final public var supportedOutputPixelFormats: [Darwin.OSType] {
    get
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public let revision: Vision.GeneratePersonSegmentationRequest.Revision
  public static let supportedRevisions: [Vision.GeneratePersonSegmentationRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct RecognizedText : Swift.Equatable, Swift.Hashable, @unchecked Swift.Sendable, Swift.CustomStringConvertible {
  public var string: Swift.String {
    get
  }
  public var confidence: Swift.Float {
    get
  }
  public var description: Swift.String {
    get
  }
  public func boundingBox(for range: Swift.Range<Swift.String.Index>) -> Vision.RectangleObservation?
  public static func == (a: Vision.RecognizedText, b: Vision.RecognizedText) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.RecognizedText : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ImageHomographicAlignmentObservation : Vision.VisionObservation {
  public let warpTransform: simd.matrix_float3x3
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func applyTransform(to ciImage: CoreImage.CIImage) -> CoreImage.CIImage
  public static func == (a: Vision.ImageHomographicAlignmentObservation, b: Vision.ImageHomographicAlignmentObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.ImageHomographicAlignmentObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.ImageHomographicAlignmentObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNImageHomographicAlignmentObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ImageAestheticsScoresObservation : Vision.VisionObservation {
  public let isUtility: Swift.Bool
  public let overallScore: Swift.Float
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public static func == (a: Vision.ImageAestheticsScoresObservation, b: Vision.ImageAestheticsScoresObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.ImageAestheticsScoresObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.ImageAestheticsScoresObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNImageAestheticsScoresObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct GeneratePersonInstanceMaskRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.InstanceMaskObservation?
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.GeneratePersonInstanceMaskRequest.Revision, b: Vision.GeneratePersonInstanceMaskRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.GeneratePersonInstanceMaskRequest.Revision, b: Vision.GeneratePersonInstanceMaskRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.GeneratePersonInstanceMaskRequest.Revision? = nil)
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.GeneratePersonInstanceMaskRequest.Revision
  public static let supportedRevisions: [Vision.GeneratePersonInstanceMaskRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.GeneratePersonInstanceMaskRequest, b: Vision.GeneratePersonInstanceMaskRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum ComputeStage : Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
  case main
  case postProcessing
  public static func == (a: Vision.ComputeStage, b: Vision.ComputeStage) -> Swift.Bool
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct GenerateForegroundInstanceMaskRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.InstanceMaskObservation?
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.GenerateForegroundInstanceMaskRequest.Revision, b: Vision.GenerateForegroundInstanceMaskRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.GenerateForegroundInstanceMaskRequest.Revision, b: Vision.GenerateForegroundInstanceMaskRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.GenerateForegroundInstanceMaskRequest.Revision? = nil)
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.GenerateForegroundInstanceMaskRequest.Revision
  public static let supportedRevisions: [Vision.GenerateForegroundInstanceMaskRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.GenerateForegroundInstanceMaskRequest, b: Vision.GenerateForegroundInstanceMaskRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct TrajectoryObservation : Vision.VisionObservation {
  public let detectedPoints: [Vision.NormalizedPoint]
  public let projectedPoints: [Vision.NormalizedPoint]
  public let equationCoefficients: simd.simd_float3
  public let movingAverageRadius: CoreFoundation.CGFloat
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.TrajectoryObservation, b: Vision.TrajectoryObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.TrajectoryObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.TrajectoryObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNTrajectoryObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectTextRectanglesRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.TextObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectTextRectanglesRequest.Revision, b: Vision.DetectTextRectanglesRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectTextRectanglesRequest.Revision, b: Vision.DetectTextRectanglesRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectTextRectanglesRequest.Revision? = nil)
  public var reportCharacterBoxes: Swift.Bool
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectTextRectanglesRequest.Revision
  public static let supportedRevisions: [Vision.DetectTextRectanglesRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectTextRectanglesRequest, b: Vision.DetectTextRectanglesRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class TrackOpticalFlowRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest, Vision.TargetedRequest {
  public typealias Result = Vision.OpticalFlowObservation?
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.TrackOpticalFlowRequest.Revision, b: Vision.TrackOpticalFlowRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.TrackOpticalFlowRequest.Revision, b: Vision.TrackOpticalFlowRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.TrackOpticalFlowRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  public enum ComputationAccuracy : Swift.CaseIterable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case low
    case medium
    case high
    case veryHigh
    public static func == (a: Vision.TrackOpticalFlowRequest.ComputationAccuracy, b: Vision.TrackOpticalFlowRequest.ComputationAccuracy) -> Swift.Bool
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.TrackOpticalFlowRequest.ComputationAccuracy]
    nonisolated public static var allCases: [Vision.TrackOpticalFlowRequest.ComputationAccuracy] {
      get
    }
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  final public var computationAccuracy: Vision.TrackOpticalFlowRequest.ComputationAccuracy {
    get
    set
  }
  final public var supportedOutputPixelFormatTypes: [Darwin.OSType] {
    get
  }
  final public var outputPixelFormatType: Darwin.OSType {
    get
    set
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public let revision: Vision.TrackOpticalFlowRequest.Revision
  public static let supportedRevisions: [Vision.TrackOpticalFlowRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct BarcodeObservation : Vision.VisionObservation, Vision.QuadrilateralProviding {
  public enum CompositeType : Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
    case gs1TypeA
    case gs1TypeB
    case gs1TypeC
    case linked
    public static func == (a: Vision.BarcodeObservation.CompositeType, b: Vision.BarcodeObservation.CompositeType) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public let payloadString: Swift.String?
  public let payloadData: Foundation.Data?
  public let supplementalPayloadString: Swift.String?
  public let supplementalPayloadData: Foundation.Data?
  public let supplementalCompositeType: Vision.BarcodeObservation.CompositeType?
  public let isGS1DataCarrier: Swift.Bool
  public let symbology: Vision.BarcodeSymbology
  public let isColorInverted: Swift.Bool
  public var topLeft: Vision.NormalizedPoint
  public var topRight: Vision.NormalizedPoint
  public var bottomRight: Vision.NormalizedPoint
  public var bottomLeft: Vision.NormalizedPoint
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.BarcodeObservation, b: Vision.BarcodeObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.BarcodeObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.BarcodeObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNBarcodeObservation)
}
@_hasMissingDesignatedInitializers @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class ImageRequestHandler : @unchecked Swift.Sendable {
  convenience public init(_ imageURL: Foundation.URL, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(_ image: CoreGraphics.CGImage, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(_ image: CoreImage.CIImage, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(_ pixelBuffer: CoreVideo.CVPixelBuffer, depthData: AVFoundation.AVDepthData? = nil, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(_ sampleBuffer: CoreMedia.CMSampleBuffer, depthData: AVFoundation.AVDepthData? = nil, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  convenience public init(_ data: Foundation.Data, orientation: ImageIO.CGImagePropertyOrientation? = nil)
  final public func perform<T>(_ request: T) async throws -> T.Result where T : Vision.VisionRequest
  final public func perform<each T>(_ request: repeat each T) async throws -> (repeat (each T).Result) where repeat each T : Vision.VisionRequest
  final public func performAll(_ requests: some Collection<any VisionRequest>) -> some _Concurrency.AsyncSequence<Vision.VisionResult, Swift.Never>
  
  @objc deinit
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct FaceObservation : Vision.VisionObservation, Vision.BoundingBoxProviding {
  public init(boundingBox: Vision.NormalizedRect, revision: Vision.DetectFaceRectanglesRequest.Revision? = nil)
  public let landmarks: Vision.FaceObservation.Landmarks2D?
  public let roll: Foundation.Measurement<Foundation.UnitAngle>
  public let yaw: Foundation.Measurement<Foundation.UnitAngle>
  public let pitch: Foundation.Measurement<Foundation.UnitAngle>
  public let captureQuality: Vision.FaceObservation.CaptureQuality?
  public var boundingBox: Vision.NormalizedRect
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.FaceObservation, b: Vision.FaceObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.FaceObservation {
  public struct CaptureQuality : Swift.Sendable, Swift.Hashable, Swift.Equatable, Swift.Codable, Swift.CustomStringConvertible {
    public let score: Swift.Float
    public let originatingRequestDescriptor: Vision.RequestDescriptor?
    public var description: Swift.String {
      get
    }
    public static func == (a: Vision.FaceObservation.CaptureQuality, b: Vision.FaceObservation.CaptureQuality) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.FaceObservation {
  public struct Landmarks2D : Swift.Codable, Swift.Equatable, Swift.Sendable, Swift.CustomStringConvertible, Swift.Hashable {
    public var allPoints: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var faceContour: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var leftEye: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var rightEye: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var leftEyebrow: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var rightEyebrow: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var nose: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var noseCrest: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var medianLine: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var outerLips: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var innerLips: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var leftPupil: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var rightPupil: Vision.FaceObservation.Landmarks2D.Region {
      get
    }
    public var description: Swift.String {
      get
    }
    public let originatingRequestDescriptor: Vision.RequestDescriptor?
    public static func == (a: Vision.FaceObservation.Landmarks2D, b: Vision.FaceObservation.Landmarks2D) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.FaceObservation.Landmarks2D {
  public struct Region : Swift.Codable, Swift.Equatable, Swift.Sendable, Swift.Hashable, Swift.CustomStringConvertible {
    public enum PointsClassification : Swift.Codable, Swift.Hashable, Swift.Sendable, Swift.Equatable {
      case closedPath
      case disconnected
      case openPath
      public static func == (a: Vision.FaceObservation.Landmarks2D.Region.PointsClassification, b: Vision.FaceObservation.Landmarks2D.Region.PointsClassification) -> Swift.Bool
      public func encode(to encoder: any Swift.Encoder) throws
      public func hash(into hasher: inout Swift.Hasher)
      public var hashValue: Swift.Int {
        get
      }
      public init(from decoder: any Swift.Decoder) throws
    }
    public let pointsClassification: Vision.FaceObservation.Landmarks2D.Region.PointsClassification
    public let points: [Vision.NormalizedPoint]
    public let precisionEstimatesPerPoint: [Swift.Float]?
    public func pointsInImageCoordinates(_ imageSize: CoreFoundation.CGSize, origin: Vision.CoordinateOrigin = .lowerLeft) -> [CoreFoundation.CGPoint]
    public func hash(into hasher: inout Swift.Hasher)
    public var description: Swift.String {
      get
    }
    public let originatingRequestDescriptor: Vision.RequestDescriptor?
    public static func == (a: Vision.FaceObservation.Landmarks2D.Region, b: Vision.FaceObservation.Landmarks2D.Region) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.FaceObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.FaceObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNFaceObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct InstanceMaskObservation : Vision.VisionObservation, @unchecked Swift.Sendable {
  public let allInstances: Foundation.IndexSet
  public let allInstancesMask: Vision.PixelBufferObservation
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public func generateMask(for instances: Foundation.IndexSet) throws -> CoreVideo.CVPixelBuffer
  public func generateMaskedImage(for instances: Foundation.IndexSet, imageFrom requestHandler: Vision.ImageRequestHandler, croppedToInstancesExtent: Swift.Bool = false) throws -> CoreVideo.CVPixelBuffer
  public func generateScaledMask(for instances: Foundation.IndexSet, scaledToImageFrom requestHandler: Vision.ImageRequestHandler) throws -> CoreVideo.CVPixelBuffer
  public func instanceAtPoint(_ point: Vision.NormalizedPoint) -> Foundation.IndexSet
  public static func == (lhs: Vision.InstanceMaskObservation, rhs: Vision.InstanceMaskObservation) -> Swift.Bool
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.InstanceMaskObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.InstanceMaskObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init?(_ observation: Vision.VNInstanceMaskObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public protocol BoundingBoxProviding {
  var boundingBox: Vision.NormalizedRect { get }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum VisionResult : Swift.Sendable {
  case calculateImageAestheticsScores(Vision.CalculateImageAestheticsScoresRequest, Vision.ImageAestheticsScoresObservation)
  case classifyImage(Vision.ClassifyImageRequest, [Vision.ClassificationObservation])
  case coreML(Vision.CoreMLRequest, [any Vision.VisionObservation])
  case detectAnimalBodyPose(Vision.DetectAnimalBodyPoseRequest, [Vision.AnimalBodyPoseObservation])
  case detectBarcodes(Vision.DetectBarcodesRequest, [Vision.BarcodeObservation])
  case detectContours(Vision.DetectContoursRequest, Vision.ContoursObservation)
  case detectDocumentSegmentation(Vision.DetectDocumentSegmentationRequest, Vision.DetectedDocumentObservation?)
  case detectFaceCaptureQuality(Vision.DetectFaceCaptureQualityRequest, [Vision.FaceObservation])
  case detectFaceLandmarks(Vision.DetectFaceLandmarksRequest, [Vision.FaceObservation])
  case detectHorizon(Vision.DetectHorizonRequest, Vision.HorizonObservation?)
  case detectHumanBodyPose(Vision.DetectHumanBodyPoseRequest, [Vision.HumanBodyPoseObservation])
  case detectHumanBodyPose3D(Vision.DetectHumanBodyPose3DRequest, [Vision.HumanBodyPose3DObservation])
  case detectHumanHandPose(Vision.DetectHumanHandPoseRequest, [Vision.HumanHandPoseObservation])
  case detectRectangles(Vision.DetectRectanglesRequest, [Vision.RectangleObservation])
  case detectTextRectangles(Vision.DetectTextRectanglesRequest, [Vision.TextObservation])
  case detectTrajectories(Vision.DetectTrajectoriesRequest, [Vision.TrajectoryObservation])
  case generateAttentionBasedSaliencyImage(Vision.GenerateAttentionBasedSaliencyImageRequest, Vision.SaliencyImageObservation)
  case generateImageFeaturePrint(Vision.GenerateImageFeaturePrintRequest, Vision.FeaturePrintObservation)
  case generateForegroundInstanceMask(Vision.GenerateForegroundInstanceMaskRequest, Vision.InstanceMaskObservation?)
  case generateObjectnessBasedSaliencyImage(Vision.GenerateObjectnessBasedSaliencyImageRequest, Vision.SaliencyImageObservation)
  case generatePersonSegmentation(Vision.GeneratePersonSegmentationRequest, Vision.PixelBufferObservation)
  case generatePersonInstanceMask(Vision.GeneratePersonInstanceMaskRequest, Vision.InstanceMaskObservation?)
  case recognizeAnimals(Vision.RecognizeAnimalsRequest, [Vision.RecognizedObjectObservation])
  case recognizeText(Vision.RecognizeTextRequest, [Vision.RecognizedTextObservation])
  case trackHomographicImageRegistration(Vision.TrackHomographicImageRegistrationRequest, Vision.ImageHomographicAlignmentObservation)
  case trackObject(Vision.TrackObjectRequest, Vision.DetectedObjectObservation?)
  case trackOpticalFlow(Vision.TrackOpticalFlowRequest, Vision.OpticalFlowObservation?)
  case trackRectangle(Vision.TrackRectangleRequest, Vision.RectangleObservation?)
  case trackTranslationalImageRegistration(Vision.TrackTranslationalImageRegistrationRequest, Vision.ImageTranslationAlignmentObservation)
  case detectFaceRectangles(Vision.DetectFaceRectanglesRequest, [Vision.FaceObservation])
  case detectHumanRectangles(Vision.DetectHumanRectanglesRequest, [Vision.HumanObservation])
  case error(any Vision.VisionRequest, any Swift.Error)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.VisionResult : Swift.Equatable, Swift.CustomStringConvertible {
  public var description: Swift.String {
    get
  }
  public static func == (lhs: Vision.VisionResult, rhs: Vision.VisionResult) -> Swift.Bool
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct SaliencyImageObservation : Vision.VisionObservation {
  public let salientObjects: [Vision.RectangleObservation]
  public let heatMap: Vision.PixelBufferObservation
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public static func == (a: Vision.SaliencyImageObservation, b: Vision.SaliencyImageObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.SaliencyImageObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.SaliencyImageObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init?(_ observation: Vision.VNSaliencyImageObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ImageTranslationAlignmentObservation : Vision.VisionObservation {
  public let alignmentTransform: CoreFoundation.CGAffineTransform
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func applyTransform(to ciImage: CoreImage.CIImage) -> CoreImage.CIImage
  public init(_ observation: Vision.VNImageTranslationAlignmentObservation)
  public static func == (a: Vision.ImageTranslationAlignmentObservation, b: Vision.ImageTranslationAlignmentObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.ImageTranslationAlignmentObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectRectanglesRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.RectangleObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectRectanglesRequest.Revision, b: Vision.DetectRectanglesRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectRectanglesRequest.Revision, b: Vision.DetectRectanglesRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectRectanglesRequest.Revision? = nil)
  public var minimumAspectRatio: Swift.Float
  public var maximumAspectRatio: Swift.Float
  public var quadratureToleranceDegrees: Swift.Float
  public var minimumSize: Swift.Float
  public var minimumConfidence: Swift.Float
  public var maximumObservations: Swift.Int
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectRectanglesRequest.Revision
  public static let supportedRevisions: [Vision.DetectRectanglesRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectRectanglesRequest, b: Vision.DetectRectanglesRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ClassifyImageRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.ClassificationObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision2
    public static func < (a: Vision.ClassifyImageRequest.Revision, b: Vision.ClassifyImageRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.ClassifyImageRequest.Revision, b: Vision.ClassifyImageRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.ClassifyImageRequest.Revision? = nil)
  public var supportedIdentifiers: [Swift.String] {
    get
  }
  public var cropAndScaleAction: Vision.ImageCropAndScaleAction
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.ClassifyImageRequest.Revision
  public static let supportedRevisions: [Vision.ClassifyImageRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.ClassifyImageRequest, b: Vision.ClassifyImageRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct RecognizeTextRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.RecognizedTextObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision3
    public static func < (a: Vision.RecognizeTextRequest.Revision, b: Vision.RecognizeTextRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.RecognizeTextRequest.Revision, b: Vision.RecognizeTextRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.RecognizeTextRequest.Revision? = nil)
  public enum RecognitionLevel : Swift.CaseIterable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case accurate
    case fast
    public static func == (a: Vision.RecognizeTextRequest.RecognitionLevel, b: Vision.RecognizeTextRequest.RecognitionLevel) -> Swift.Bool
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.RecognizeTextRequest.RecognitionLevel]
    nonisolated public static var allCases: [Vision.RecognizeTextRequest.RecognitionLevel] {
      get
    }
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public var minimumTextHeightFraction: Swift.Float
  public var recognitionLevel: Vision.RecognizeTextRequest.RecognitionLevel
  public var automaticallyDetectsLanguage: Swift.Bool
  public var recognitionLanguages: [Foundation.Locale.Language]
  public var usesLanguageCorrection: Swift.Bool
  public var customWords: [Swift.String]
  public var supportedRecognitionLanguages: [Foundation.Locale.Language] {
    get
  }
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.RecognizeTextRequest.Revision
  public static let supportedRevisions: [Vision.RecognizeTextRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.RecognizeTextRequest, b: Vision.RecognizeTextRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class TrackRectangleRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest {
  public typealias Result = Vision.RectangleObservation?
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.TrackRectangleRequest.Revision, b: Vision.TrackRectangleRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.TrackRectangleRequest.Revision, b: Vision.TrackRectangleRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(detectedRectangle: any Vision.QuadrilateralProviding & Vision.VisionObservation, _ revision: Vision.TrackRectangleRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  public enum TrackingLevel : Swift.CaseIterable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case accurate
    case fast
    public static func == (a: Vision.TrackRectangleRequest.TrackingLevel, b: Vision.TrackRectangleRequest.TrackingLevel) -> Swift.Bool
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.TrackRectangleRequest.TrackingLevel]
    nonisolated public static var allCases: [Vision.TrackRectangleRequest.TrackingLevel] {
      get
    }
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  final public let inputObservation: any Vision.QuadrilateralProviding & Vision.VisionObservation
  final public var trackingLevel: Vision.TrackRectangleRequest.TrackingLevel {
    get
    set
  }
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public let revision: Vision.TrackRectangleRequest.Revision
  public static let supportedRevisions: [Vision.TrackRectangleRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
public typealias DetectorKey = Swift.String
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct HumanObservation : Vision.VisionObservation, Vision.BoundingBoxProviding {
  public let isUpperBodyOnly: Swift.Bool
  public let boundingBox: Vision.NormalizedRect
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.HumanObservation, b: Vision.HumanObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.HumanObservation {
  public init(boundingBox: Vision.NormalizedRect, revision: Vision.DetectHumanRectanglesRequest.Revision? = nil)
}
extension Vision.HumanObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNHumanObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectContoursRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.ContoursObservation
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectContoursRequest.Revision, b: Vision.DetectContoursRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectContoursRequest.Revision, b: Vision.DetectContoursRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectContoursRequest.Revision? = nil)
  public var contrastAdjustment: Swift.Float
  public var contrastPivot: Swift.Float?
  public var detectsDarkOnLight: Swift.Bool
  public var maximumImageDimension: Swift.Int
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectContoursRequest.Revision
  public static let supportedRevisions: [Vision.DetectContoursRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectContoursRequest, b: Vision.DetectContoursRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum ImageCropAndScaleAction : Swift.CaseIterable, Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
  case centerCrop
  case scaleToFit
  case scaleToFill
  case scaleToFitPlus90CCWRotation
  case scaleToFillPlus90CCWRotation
  public static func == (a: Vision.ImageCropAndScaleAction, b: Vision.ImageCropAndScaleAction) -> Swift.Bool
  @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
  public typealias AllCases = [Vision.ImageCropAndScaleAction]
  nonisolated public static var allCases: [Vision.ImageCropAndScaleAction] {
    get
  }
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ImagePixelDimensions {
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum Chirality : Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
  case left
  case right
  public static func == (a: Vision.Chirality, b: Vision.Chirality) -> Swift.Bool
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum BarcodeSymbology : Swift.CaseIterable, Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
  case aztec
  case code39
  case code39Checksum
  case code39FullASCII
  case code39FullASCIIChecksum
  case code93
  case code93i
  case code128
  case dataMatrix
  case ean8
  case ean13
  case i2of5
  case i2of5Checksum
  case itf14
  case pdf417
  case qr
  case upce
  case codabar
  case gs1DataBar
  case gs1DataBarExpanded
  case gs1DataBarLimited
  case microPDF417
  case microQR
  case msiPlessey
  public static func == (a: Vision.BarcodeSymbology, b: Vision.BarcodeSymbology) -> Swift.Bool
  @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
  public typealias AllCases = [Vision.BarcodeSymbology]
  nonisolated public static var allCases: [Vision.BarcodeSymbology] {
    get
  }
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public enum ElementType : Swift.Codable, Swift.Equatable, Swift.Hashable, Swift.Sendable {
  case float
  case double
  public static func == (a: Vision.ElementType, b: Vision.ElementType) -> Swift.Bool
  public func encode(to encoder: any Swift.Encoder) throws
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public init(from decoder: any Swift.Decoder) throws
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectFaceRectanglesRequest : Vision.ImageProcessingRequest {
  public typealias Result = [Vision.FaceObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision3
    public static func < (a: Vision.DetectFaceRectanglesRequest.Revision, b: Vision.DetectFaceRectanglesRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectFaceRectanglesRequest.Revision, b: Vision.DetectFaceRectanglesRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectFaceRectanglesRequest.Revision? = nil)
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectFaceRectanglesRequest.Revision
  public static let supportedRevisions: [Vision.DetectFaceRectanglesRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectFaceRectanglesRequest, b: Vision.DetectFaceRectanglesRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct NormalizedCircle {
  public init(center: Vision.NormalizedPoint, radius: CoreFoundation.CGFloat)
  public let center: Vision.NormalizedPoint
  public let radius: CoreFoundation.CGFloat
  public func contains(_ point: Vision.NormalizedPoint) -> Swift.Bool
  public func contains(_ point: Vision.NormalizedPoint, inCircumferentialRingOfWidth ringWidth: CoreFoundation.CGFloat) -> Swift.Bool
  public static var zero: Vision.NormalizedCircle {
    get
  }
  public static func boundingCircle(for points: [Vision.NormalizedPoint]) -> Vision.NormalizedCircle
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectedDocumentObservation : Vision.VisionObservation, Vision.QuadrilateralProviding {
  public var globalSegmentationMask: Vision.PixelBufferObservation
  public var topLeft: Vision.NormalizedPoint
  public var topRight: Vision.NormalizedPoint
  public var bottomRight: Vision.NormalizedPoint
  public var bottomLeft: Vision.NormalizedPoint
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public static func == (a: Vision.DetectedDocumentObservation, b: Vision.DetectedDocumentObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.DetectedDocumentObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.DetectedDocumentObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init?(_ observation: Vision.VNRectangleObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct HumanBodyPoseObservation : Vision.VisionObservation, Vision.PoseProviding {
  public var keypoints: CoreML.MLMultiArray {
    get throws
  }
  public func allJoints(in groupName: Vision.HumanBodyPoseObservation.PoseJointsGroupName? = nil) -> [Vision.HumanBodyPoseObservation.PoseJointName : Vision.Joint]
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public typealias PoseJointName = Vision.HumanBodyPoseObservation.JointName
  public typealias PoseJointsGroupName = Vision.HumanBodyPoseObservation.JointsGroupName
  public enum JointName : Swift.String, Swift.Hashable, Swift.Sendable, Swift.Codable {
    case leftEar
    case leftEye
    case rightEar
    case rightEye
    case neck
    case nose
    case leftShoulder
    case leftElbow
    case leftWrist
    case rightShoulder
    case rightElbow
    case rightWrist
    case root
    case leftHip
    case leftKnee
    case leftAnkle
    case rightHip
    case rightKnee
    case rightAnkle
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public enum JointsGroupName : Swift.String, Swift.CaseIterable, Swift.Hashable, Swift.Sendable {
    case face
    case torso
    case leftArm
    case rightArm
    case leftLeg
    case rightLeg
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.HumanBodyPoseObservation.JointsGroupName]
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    nonisolated public static var allCases: [Vision.HumanBodyPoseObservation.JointsGroupName] {
      get
    }
    public var rawValue: Swift.String {
      get
    }
  }
  public let leftHand: Vision.HumanHandPoseObservation?
  public let rightHand: Vision.HumanHandPoseObservation?
  public static func == (a: Vision.HumanBodyPoseObservation, b: Vision.HumanBodyPoseObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanBodyPoseObservation : Swift.Codable {
  public init(from decoder: any Swift.Decoder) throws
  public func encode(to encoder: any Swift.Encoder) throws
}
extension Vision.HumanBodyPoseObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNHumanBodyPoseObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectHorizonRequest : Vision.ImageProcessingRequest {
  public typealias Result = Vision.HorizonObservation?
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectHorizonRequest.Revision, b: Vision.DetectHorizonRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectHorizonRequest.Revision, b: Vision.DetectHorizonRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectHorizonRequest.Revision? = nil)
  public var regionOfInterest: Vision.NormalizedRect
  public let revision: Vision.DetectHorizonRequest.Revision
  public static let supportedRevisions: [Vision.DetectHorizonRequest.Revision]
  public var descriptor: Vision.RequestDescriptor {
    get
  }
  public static func == (a: Vision.DetectHorizonRequest, b: Vision.DetectHorizonRequest) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct DetectedObjectObservation : Vision.VisionObservation, Vision.BoundingBoxProviding {
  public init(boundingBox: Vision.NormalizedRect)
  public var boundingBox: Vision.NormalizedRect
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public static func == (a: Vision.DetectedObjectObservation, b: Vision.DetectedObjectObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.DetectedObjectObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.DetectedObjectObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNDetectedObjectObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ContoursObservation : Vision.VisionObservation, @unchecked Swift.Sendable {
  public var contourCount: Swift.Int {
    get
  }
  public var normalizedPath: CoreGraphics.CGPath {
    get
  }
  public var topLevelContours: [Vision.ContoursObservation.Contour] {
    get
  }
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func contourAtIndex(_ index: Swift.Int) -> Vision.ContoursObservation.Contour?
  public func countourAtIndexPath(_ indexPath: Foundation.IndexPath) -> Vision.ContoursObservation.Contour?
  public static func == (a: Vision.ContoursObservation, b: Vision.ContoursObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.ContoursObservation {
  public struct Contour : @unchecked Swift.Sendable, Swift.Equatable, Swift.Hashable, Swift.CustomStringConvertible {
    public var aspectRatio: Swift.Float {
      get
    }
    public var indexPath: Foundation.IndexPath {
      get
    }
    public var normalizedPath: CoreGraphics.CGPath {
      get
    }
    public var pointCount: Swift.Int {
      get
    }
    public var normalizedPoints: [simd.simd_float2] {
      get
    }
    public var childContours: [Vision.ContoursObservation.Contour] {
      get
    }
    public var description: Swift.String {
      get
    }
    public func calculateArea(useOrientedArea: Swift.Bool = false) -> Swift.Double
    public func calculatePerimeter() -> Swift.Double
    public func boundingCircle() -> Vision.NormalizedCircle
    public func polygonApproximation(epsilon: Swift.Float) throws -> Vision.ContoursObservation.Contour
    public static func == (a: Vision.ContoursObservation.Contour, b: Vision.ContoursObservation.Contour) -> Swift.Bool
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.ContoursObservation : Swift.Codable {
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
extension Vision.ContoursObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNContoursObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct AnimalBodyPoseObservation : Vision.VisionObservation, Vision.PoseProviding {
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var description: Swift.String {
    get
  }
  public func allJoints(in groupName: Vision.AnimalBodyPoseObservation.PoseJointsGroupName? = nil) -> [Vision.AnimalBodyPoseObservation.PoseJointName : Vision.Joint]
  public typealias PoseJointName = Vision.AnimalBodyPoseObservation.JointName
  public typealias PoseJointsGroupName = Vision.AnimalBodyPoseObservation.JointsGroupName
  public enum JointName : Swift.String, Swift.Hashable, Swift.Sendable, Swift.Codable {
    case leftEarTop
    case leftEarMiddle
    case leftEarBottom
    case leftEye
    case neck
    case nose
    case rightEye
    case rightEarTop
    case rightEarMiddle
    case rightEarBottom
    case leftBackElbow
    case leftFrontElbow
    case rightFrontElbow
    case rightBackElbow
    case leftBackKnee
    case leftFrontKnee
    case rightBackKnee
    case rightFrontKnee
    case leftBackPaw
    case leftFrontPaw
    case rightBackPaw
    case rightFrontPaw
    case tailTop
    case tailMiddle
    case tailBottom
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public enum JointsGroupName : Swift.String, Swift.CaseIterable, Swift.Hashable, Swift.Sendable {
    case forelegs
    case head
    case hindlegs
    case tail
    case trunk
    public init?(rawValue: Swift.String)
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias AllCases = [Vision.AnimalBodyPoseObservation.JointsGroupName]
    @available(iOS 18.0, tvOS 18.0, visionOS 2.0, macOS 15.0, *)
    public typealias RawValue = Swift.String
    nonisolated public static var allCases: [Vision.AnimalBodyPoseObservation.JointsGroupName] {
      get
    }
    public var rawValue: Swift.String {
      get
    }
  }
  public static func == (a: Vision.AnimalBodyPoseObservation, b: Vision.AnimalBodyPoseObservation) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.AnimalBodyPoseObservation : Swift.Codable {
  public init(from decoder: any Swift.Decoder) throws
  public func encode(to encoder: any Swift.Encoder) throws
}
extension Vision.AnimalBodyPoseObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init(_ observation: Vision.VNAnimalBodyPoseObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct ImageCoordinateConversionHelpers {
  public static func imagePointForNormalizedPoint(normalizedPoint: CoreFoundation.CGPoint, imageSize: CoreFoundation.CGSize) -> CoreFoundation.CGPoint
  public static func verticallyFlippedImagePoint(imagePoint: CoreFoundation.CGPoint, imageHeight: Swift.UInt32) -> CoreFoundation.CGPoint
  public static func verticallyFlippedNormalizedPoint(normalizedPoint: CoreFoundation.CGPoint) -> CoreFoundation.CGPoint
  public static func imageRectForNormalizedRect(normalizedRect: CoreFoundation.CGRect, imageSize: CoreFoundation.CGSize) -> CoreFoundation.CGRect
  public static func verticallyFlippedImageRect(imageRect: CoreFoundation.CGRect, imageHeight: Swift.UInt32) -> CoreFoundation.CGRect
  public static func verticallyFlippedNormalizedRect(normalizedRect: CoreFoundation.CGRect, imageHeight: Swift.UInt32) -> CoreFoundation.CGRect
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
public struct PixelBufferObservation : Vision.VisionObservation, @unchecked Swift.Sendable {
  public var size: CoreFoundation.CGSize {
    get
  }
  public var pixelFormat: Darwin.OSType {
    get
  }
  public var cgImage: CoreGraphics.CGImage {
    get throws
  }
  public let uuid: Foundation.UUID
  public let confidence: Swift.Float
  public let timeRange: CoreMedia.CMTimeRange?
  public var description: Swift.String {
    get
  }
  public func withUnsafePointer<R>(_ body: (Swift.UnsafeRawPointer) -> R) -> R
  public func pixel(at point: Vision.NormalizedPoint) -> Swift.Float
  public static func == (lhs: Vision.PixelBufferObservation, rhs: Vision.PixelBufferObservation) -> Swift.Bool
  public let originatingRequestDescriptor: Vision.RequestDescriptor?
  public var hashValue: Swift.Int {
    get
  }
}
extension Vision.PixelBufferObservation {
  @available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
  public init?(_ observation: Vision.VNPixelBufferObservation)
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
final public class DetectHumanBodyPose3DRequest : Vision.ImageProcessingRequest, Vision.StatefulRequest {
  public typealias Result = [Vision.HumanBodyPose3DObservation]
  public enum Revision : Swift.Comparable, Swift.Sendable, Swift.Equatable, Swift.Codable, Swift.Hashable {
    case revision1
    public static func < (a: Vision.DetectHumanBodyPose3DRequest.Revision, b: Vision.DetectHumanBodyPose3DRequest.Revision) -> Swift.Bool
    public static func == (a: Vision.DetectHumanBodyPose3DRequest.Revision, b: Vision.DetectHumanBodyPose3DRequest.Revision) -> Swift.Bool
    public func encode(to encoder: any Swift.Encoder) throws
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
    public init(from decoder: any Swift.Decoder) throws
  }
  public init(_ revision: Vision.DetectHumanBodyPose3DRequest.Revision? = nil, frameAnalysisSpacing: CoreMedia.CMTime? = nil)
  final public var supportedJointNames: [Vision.HumanBodyPose3DObservation.JointName] {
    get
  }
  final public var supportedJointsGroupNames: [Vision.HumanBodyPose3DObservation.JointsGroupName] {
    get
  }
  final public var regionOfInterest: Vision.NormalizedRect {
    get
    set
  }
  final public var minimumLatencyFrameCount: Swift.Int {
    get
  }
  final public let frameAnalysisSpacing: CoreMedia.CMTime
  final public let revision: Vision.DetectHumanBodyPose3DRequest.Revision
  public static let supportedRevisions: [Vision.DetectHumanBodyPose3DRequest.Revision]
  final public var descriptor: Vision.RequestDescriptor {
    get
  }
  @objc deinit
  final public var hashValue: Swift.Int {
    get
  }
}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanBodyPose3DObservation.JointName : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanBodyPose3DObservation.JointsGroupName : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.CoordinateOrigin : Swift.Equatable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.CoordinateOrigin : Swift.Hashable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanHandPoseObservation.JointName : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanHandPoseObservation.JointsGroupName : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.RecognizeAnimalsRequest.Animal : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanBodyPoseObservation.JointName : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.HumanBodyPoseObservation.JointsGroupName : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.AnimalBodyPoseObservation.JointName : Swift.RawRepresentable {}
@available(macOS 15.0, iOS 18.0, tvOS 18.0, visionOS 2.0, *)
extension Vision.AnimalBodyPoseObservation.JointsGroupName : Swift.RawRepresentable {}
